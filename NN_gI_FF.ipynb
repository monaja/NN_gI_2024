{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.system('cls')  # On Windows System\n",
    "\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('reset','-sf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Import numpy\n",
    "import matplotlib.pyplot as plt # Import pyplot\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the features and the labels for the training data and the test data\n",
    "# import the training data\n",
    "# train_data = pd.read_csv('train.csv')\n",
    "# test_data = pd.read_csv('test.csv')\n",
    "\n",
    "train_data = np.loadtxt('train.csv', delimiter=',', skiprows=1) \n",
    "test_data = np.loadtxt('test.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "train_data = train_data[:800]\n",
    "test_data = test_data[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(0.5 * len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = test_data[:split_index]\n",
    "test_data = test_data[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the training data using z-normalization \n",
    "mean = np.mean(train_data, axis=0)\n",
    "std = np.std(train_data, axis=0)\n",
    "normalized_train_data = (train_data - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the training data using z-normalization but using the training data mean and standard deviation\n",
    "# normalize the data using z-normalization \n",
    "normalized_test_data = (test_data - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid() function (activation function)\n",
    "def sigmoid(x):\n",
    "    fAct = 1/(1+np.exp(-1*x))\n",
    "    return fAct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivation of the activation fucntion\n",
    "def derived_sigmoid(x):\n",
    "    fAct = 1/(1+np.exp(-1*x))\n",
    "    DfAct = fAct*(1-fAct)\n",
    "    return DfAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate m*n matrix, initial values are zeros\n",
    "def makematrix(m, n, fill=0.0):\n",
    "    a = []\n",
    "    for i in range(m):\n",
    "        a.append([fill]*n)\n",
    "    return np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random data\n",
    "def random_number(a,b):\n",
    "    return (b-a)*np.random.normal()+a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normalized_test_data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from the weights\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#BP Neural Networks\n",
    "class BPNN:\n",
    "    def __init__(self, num_in, num_hidden, num_out):\n",
    "        # Nodes of input, hidden, output layers\n",
    "        self.num_in = num_in + 1  # Add one bias node\n",
    "        self.num_hidden = num_hidden + 1   # Add one bias node\n",
    "        # self.num1_hidden = num1_hidden + 1\n",
    "        self.num_out = num_out\n",
    "        \n",
    "        # Activate all nodes (vector)\n",
    "        self.active_in = np.array([1.0]*self.num_in)\n",
    "        self.active_hidden = np.array([1.0]*self.num_hidden)\n",
    "        # self.active_hidden1 = np.array([1.0]*self.num1_hidden)\n",
    "        self.active_out = np.array([1.0]*self.num_out)\n",
    "\n",
    "        # load the weights\n",
    "        # Load the weights from the file\n",
    "        loaded_weights = np.load('weights.npy', allow_pickle=True) \n",
    "        print(\"Loading data from the weights\")\n",
    "        print(loaded_weights)\n",
    "        \n",
    "        # Create weight matrices\n",
    "        self.wight_in = makematrix(self.num_in, self.num_hidden-1)\n",
    "        # self.wight_in1 = makematrix(self.num_hidden, self.num1_hidden-1)\n",
    "        self.wight_out = makematrix(self.num_hidden, self.num_out)\n",
    "        \n",
    "        \n",
    "              \n",
    "    # Feed-forward\n",
    "    def Feedforward(self, inputs):\n",
    "        if np.shape(inputs)[1] != self.num_in-1:\n",
    "            raise ValueError('Incorrect input numbers')\n",
    "        # Input layer values\n",
    "        self.active_in[1:self.num_in]=inputs\n",
    "        \n",
    "        # Hidden layer values\n",
    "        self.sum_hidden=np.dot(self.wight_in.T,np.array([self.active_in]).T)\n",
    "        self.active_hidden = np.vstack( (1, sigmoid(self.sum_hidden)) )   # Activation function\n",
    "        \n",
    "        # Output layer values\n",
    "        self.sum_out=np.dot(self.wight_out.T,self.active_hidden)\n",
    "        self.active_out = self.sum_out # or sigmoid(self.sum_out)\n",
    "        return self.active_out\n",
    " \n",
    "    # Backpropagation\n",
    "    def errorbackpropagate(self, targets):   # lr is the learning rate\n",
    "        if self.num_out==1:\n",
    "            targets=targets\n",
    "        if np.shape(targets)[1] != self.num_out:\n",
    "            raise ValueError('Incorrect Output numbers')\n",
    "        # Cost function\n",
    "        self.error=(1/2)*np.dot((self.active_out-targets.T).T,(self.active_out-targets.T))\n",
    "        \n",
    "        # dJ/dw_out\n",
    "        self.gradient_out = (self.active_out-targets.T) #*derived_sigmoid(self.sum_out)#dJ/dx\n",
    "        self.gradient_w_out = np.dot(self.gradient_out,self.active_hidden.T).T #dx/dw_out\n",
    "        \n",
    "        # dJ/dw_in\n",
    "        self.gradient_hidden = np.dot(self.wight_out[1:],self.gradient_out)*derived_sigmoid(self.sum_hidden) #dJ/dx\n",
    "        self.gradient_w_in = np.dot(self.gradient_hidden,np.array([self.active_in])).T #dx/dw_in\n",
    "       \n",
    "        return self.error\n",
    "\n",
    "    def train(self, pattern, itera=1000, lr = 0.05):\n",
    "        error = 1000\n",
    "        i=0\n",
    "        # while(error < 185):\n",
    "        for i in range(itera):\n",
    "            Gradient_out = 0.0\n",
    "            Gradient_in = 0.0\n",
    "            error = 0\n",
    "            i+=1\n",
    "            for j in pattern:\n",
    "                inputs = np.array([j[0:self.num_in-1]])\n",
    "                \n",
    "                targets = np.array([j[self.num_in-1:]])\n",
    "                self.Feedforward(inputs)\n",
    "                self.errorbackpropagate(targets)\n",
    "                Gradient_out = Gradient_out + self.gradient_w_out\n",
    "                Gradient_in = Gradient_in + self.gradient_w_in\n",
    "            \n",
    "                error = error + self.error\n",
    "                \n",
    "            [Tm,Tn] = np.shape(pattern)\n",
    "            self.wight_out = self.wight_out - lr*Gradient_out/Tm\n",
    "            self.wight_in = self.wight_in - lr*Gradient_in/Tm \n",
    "            \n",
    "            # if i % 10 == 0:\n",
    "            #     print('################# error %-.5f##################The %d th iteration' %(error,i))\n",
    "    # Weights\n",
    "    def weights(self):\n",
    "        print(\"input weights\")\n",
    "        print(self.wight_in)\n",
    "        print(\"Output weights\")\n",
    "        print(self.wight_out)\n",
    "        \n",
    "    # Test prediction\n",
    "    def test(self, patterns):\n",
    "        Pre = []\n",
    "        for i in patterns:\n",
    "            inputs = np.array([i[0:self.num_in-1]])\n",
    "            Pre.append( self.Feedforward(inputs) )\n",
    "            # print(Pre)\n",
    "        return Pre         \n",
    "\n",
    "\n",
    "n = BPNN(10, 16, 1) #Create neural networK  \n",
    "# n.train(normalized_train_data) # Training BP\n",
    "     \n",
    "# d=n.test(normalized_test_data)\n",
    "# len(d)\n",
    "# y_pred = np.zeros((len(normalized_test_data[:,0]),))\n",
    "# for i in range(len(d)):\n",
    "#   y_pred[i] = d[i][0,0]\n",
    "    \n",
    "# n.weights() # check weights\n",
    "# np.save('weights.npy', n.weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "187.65572"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
