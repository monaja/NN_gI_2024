{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.system('cls')  # On Windows System\n",
    "\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('reset','-sf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Import numpy\n",
    "import matplotlib.pyplot as plt # Import pyplot\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the features and the labels for the training data and the test data\n",
    "# import the training data\n",
    "train_dataset = pd.read_csv('train_800.csv',skiprows=1)\n",
    "val_dataset = pd.read_csv('eval_100.csv', skiprows=1)\n",
    "test_dataset = pd.read_csv('test_100.csv', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1233.6186253090575  1549.2746207462244  1  0  793.0457372249411  1.1  0.1  \\\n",
      "0          636.228656         1018.047388  0  0           0.000000    0    0   \n",
      "1         1404.845637         1593.716730  1  1         891.613793    0    2   \n",
      "2         1685.802010         1873.436626  0  0         537.673031    0    0   \n",
      "3         1403.021557         1560.537410  0  0           0.000000    0    0   \n",
      "4         1628.497747         2230.168744  1  0         793.045737    1    0   \n",
      "\n",
      "   327.0862956038658  0.2  3      11.45  \n",
      "0         234.349934    0  4   2.766667  \n",
      "1         361.056112    4  8  21.116667  \n",
      "2         373.024338    0  0   3.716667  \n",
      "3         371.836468    0  9   3.333333  \n",
      "4         605.064940    1  1   9.950000  \n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dividing each dataset into X (features) and y (taxi_time)\n",
    "X_train = train_dataset.iloc[:, :10].to_numpy() # First 10 columns for features\n",
    "y_train = train_dataset.iloc[:, -1].to_numpy() # Last column for target\n",
    "\n",
    "X_val = val_dataset.iloc[:, :10].to_numpy()\n",
    "y_val = val_dataset.iloc[:, -1].to_numpy().reshape(-1,1)\n",
    "\n",
    "X_test = test_dataset.iloc[:, :10].to_numpy()\n",
    "y_test = test_dataset.iloc[:, -1].to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize features (using StandardScalar from SKlearn)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize target (z-normalization) for the y dataset\n",
    "y_mean = np.mean(y_train)\n",
    "y_std = np.std(y_train)\n",
    "y_train_normalized = (y_train - y_mean) / y_std\n",
    "y_val_normalized = (y_val - y_mean) / y_std\n",
    "y_test_normalized = (y_test - y_mean) / y_std\n",
    "\n",
    "#reshape the vectors because it was giving error with (802,) to (802,1)\n",
    "\n",
    "y_train_normalized = y_train_normalized.reshape(-1,1)\n",
    "y_val_normalized =  y_val_normalized.reshape(-1,1)\n",
    "y_test_normalized =  y_test_normalized.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Leaky ReLU activation function and its derivative\n",
    "def leaky_relu(x, alpha=0.01):\n",
    "    return np.where(x > 0, x, alpha * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu_derivative(x, alpha=0.01):\n",
    "    return np.where(x > 0, 1, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the Mean Squared Error loss function and its derivative\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mse_loss_derivative(y_true, y_pred):\n",
    "    return -(2 / y_true.shape[0]) * (y_true - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error metrics functions\n",
    "def error_analysis(y_true, y_pred, epsilon=1e-10): \n",
    "   print(\"RMSE: \", np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "   print(\"MSE: \", np.mean((y_true - y_pred) ** 2))\n",
    "   print(\"MRE: \", np.mean(np.abs((y_true - y_pred) / (y_true+epsilon))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the neural network\n",
    "class NeuralNetwork: \n",
    "    def __init__(self, input_size, hlayer1_size, hlayer2_size, output_size, alpha=0.01):\n",
    "        self.alpha = alpha\n",
    "        # Initialize weights and biases using HE initialization best for LeakyRelu\n",
    "        self.weights1 = np.random.randn(input_size, hlayer1_size) * np.sqrt(2/input_size)\n",
    "        self.biases1 = np.zeros((1, hlayer1_size))\n",
    "        self.weights2 = np.random.randn(hlayer1_size, hlayer2_size) * np.sqrt(2/hlayer1_size)\n",
    "        self.biases2 = np.zeros((1, hlayer2_size))\n",
    "        self.weights3 = np.random.randn(hlayer2_size, output_size) * np.sqrt(2/hlayer2_size)\n",
    "        self.biases3 = np.zeros((1, output_size))\n",
    "\n",
    "        # np.sqrt(2 / hlayer1_size)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # Forward propagation\n",
    "        self.input = X\n",
    "        self.hlayer1 = leaky_relu(np.dot(X, self.weights1) + self.biases1, self.alpha)\n",
    "        self.hlayer2 = leaky_relu(np.dot(self.hlayer1, self.weights2) + self.biases2, self.alpha)\n",
    "        self.output = np.dot(self.hlayer2, self.weights3) + self.biases3\n",
    "        return self.output\n",
    "    \n",
    "    def valforward(self, X):\n",
    "        # Forward propagation  \n",
    "        return np.dot((leaky_relu(np.dot((leaky_relu(np.dot(X, self.weights1) + self.biases1, self.alpha)), self.weights2) + self.biases2, self.alpha)), self.weights3) + self.biases3\n",
    "        \n",
    "    def backward(self, X, y, y_pred, lambda_reg=0.001):\n",
    "        # Backpropagation\n",
    "        output_error = mse_loss_derivative(y, y_pred)\n",
    "        output_delta = output_error  # No activation in the output layer since we want it to be continuous\n",
    "        \n",
    "        hlayer2_error = np.dot(output_delta, self.weights3.T)\n",
    "        hlayer2_delta = hlayer2_error * leaky_relu_derivative(self.hlayer2, self.alpha)\n",
    "        \n",
    "        hlayer1_error = np.dot(hlayer2_delta, self.weights2.T)\n",
    "        hlayer1_delta = hlayer1_error * leaky_relu_derivative(self.hlayer1, self.alpha)\n",
    "         \n",
    "        # updating the weights -> added regularizationk term after model overfiting\n",
    "        # Assuming `weights` is a list of weight matrices\n",
    "        m = len(y)\n",
    "        \n",
    "        # l2_term_weight3 = (lambda_reg * sum(self.weights3))/m\n",
    "        # l2_term_weight2 = (lambda_reg * sum(self.weights2))/m\n",
    "        # l2_term_weight1 = (lambda_reg * sum(self.weights1))/m\n",
    "\n",
    "\n",
    "\n",
    "        l2_term_weight3 =  lambda_reg * self.weights3\n",
    "        l2_term_weight2 = lambda_reg * self.weights2\n",
    "        l2_term_weight1 = lambda_reg * self.weights1\n",
    "\n",
    "        # self.weights3 -= (np.dot(self.hlayer2.T, output_delta)) * self.learning_rate\n",
    "        # self.biases3 -= np.sum(output_delta, axis=0, keepdims=True) * self.learning_rate\n",
    "        # self.weights2 -= (np.dot(self.hlayer1.T, hlayer2_delta)) * self.learning_rate\n",
    "        # self.biases2 -= np.sum(hlayer2_delta, axis=0, keepdims=True) * self.learning_rate\n",
    "        # self.weights1 -= (np.dot(X.T, hlayer1_delta))* self.learning_rate\n",
    "        # self.biases1 -= np.sum(hlayer1_delta, axis=0, keepdims=True) * self.learning_rate\n",
    "    \n",
    "        self.weights3 -= (np.dot(self.hlayer2.T, output_delta) + l2_term_weight3) * self.learning_rate\n",
    "        self.biases3 -= np.sum(output_delta, axis=0, keepdims=True) * self.learning_rate\n",
    "        self.weights2 -= (np.dot(self.hlayer1.T, hlayer2_delta) + l2_term_weight2) * self.learning_rate\n",
    "        self.biases2 -= np.sum(hlayer2_delta, axis=0, keepdims=True) * self.learning_rate\n",
    "        self.weights1 -= (np.dot(X.T, hlayer1_delta) + l2_term_weight1)* self.learning_rate\n",
    "        self.biases1 -= np.sum(hlayer1_delta, axis=0, keepdims=True) * self.learning_rate\n",
    "\n",
    "    def train(self, X, y, iterations, learning_rate, lambda_reg):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lambda_rg = lambda_reg\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "\n",
    "        for iter in range(iterations):\n",
    "            # Forward propagation of training data\n",
    "            y_pred = self.forward(X)\n",
    "            # Compute train loss\n",
    "            train_loss = mse_loss(y, y_pred)\n",
    "\n",
    "            # #Forward propagation of validation data\n",
    "            y_valid_pred = self.valforward(X_val)\n",
    "\n",
    "            y_t_pred = self.valforward(X)\n",
    "            train1_loss = mse_loss(y, y_t_pred)\n",
    "\n",
    "            # #compute val loss \n",
    "            val_loss = mse_loss(y_val_normalized, y_valid_pred) \n",
    "\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            # Backward propagartion\n",
    "            self.backward(X, y, y_pred, lambda_reg)\n",
    "\n",
    "            # loss after every 100 iterations\n",
    "            if iter % 100 == 0:\n",
    "                print(f\"Training|TrainLoss: {train_loss}|Train1Loss: {train1_loss}|ValidLoss: {val_loss}|Iteration: {iter}\")\n",
    "            \n",
    "            #save weights after every 100k iterations\n",
    "            if iter > 0 and iter % 1000 == 0:\n",
    "                # Get current date in YYYYMMDD format\n",
    "                current_date = datetime.now().strftime('%Y%m%d%H%M%S') \n",
    "\n",
    "                # Create the files to store the weights with date and iteration number\n",
    "                weights1_file = f'weights2/weights1_{current_date}_{iter}.npy'\n",
    "                biases1_file = f'weights2/biases1_{current_date}_{iter}.npy'  \n",
    "                weights2_file = f'weights2/weights2_{current_date}_{iter}.npy'\n",
    "                biases2_file = f'weights2/biases2_{current_date}_{iter}.npy'   \n",
    "                weights3_file = f'weights2/weights3_{current_date}_{iter}.npy'\n",
    "                biases3_file = f'weights2/biases3_{current_date}_{iter}.npy' \n",
    "                losses_file = f'weights2/losses_{current_date}_{iter}.npy' \n",
    "\n",
    "                #create losses dictionary\n",
    "                lossesdata = {'train_loss': train_loss, 'valid_loss': val_loss}\n",
    " \n",
    "                np.save(weights1_file, self.weights1)\n",
    "                np.save(biases1_file, self.biases1)\n",
    "                np.save(weights2_file, self.weights2)\n",
    "                np.save(biases2_file, self.biases2)\n",
    "                np.save(weights3_file, self.weights3)\n",
    "                np.save(biases3_file, self.biases3)\n",
    "                np.save(losses_file, lossesdata)\n",
    "\n",
    "        # showing losses\n",
    "        plt.plot(train_losses, label='Training Loss')\n",
    "        plt.plot(val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training|TrainLoss: 4.262492252748129|Train1Loss: 4.262492252748129|ValidLoss: 3.2039903460043515|Iteration: 0\n",
      "Training|TrainLoss: 0.49791378107400336|Train1Loss: 0.49791378107400336|ValidLoss: 0.4807620493523084|Iteration: 100\n",
      "Training|TrainLoss: 0.4640679775244239|Train1Loss: 0.4640679775244239|ValidLoss: 0.46131476775312463|Iteration: 200\n",
      "Training|TrainLoss: 0.44865309408841625|Train1Loss: 0.44865309408841625|ValidLoss: 0.4583641158618675|Iteration: 300\n",
      "Training|TrainLoss: 0.439614873558902|Train1Loss: 0.439614873558902|ValidLoss: 0.4557273665989762|Iteration: 400\n",
      "Training|TrainLoss: 0.4333365614726115|Train1Loss: 0.4333365614726115|ValidLoss: 0.4518717814330393|Iteration: 500\n",
      "Training|TrainLoss: 0.4284958316609788|Train1Loss: 0.4284958316609788|ValidLoss: 0.448871826947293|Iteration: 600\n",
      "Training|TrainLoss: 0.42455987691468833|Train1Loss: 0.42455987691468833|ValidLoss: 0.44598360109140456|Iteration: 700\n",
      "Training|TrainLoss: 0.4212883791986297|Train1Loss: 0.4212883791986297|ValidLoss: 0.4435773920523998|Iteration: 800\n",
      "Training|TrainLoss: 0.41847423630651803|Train1Loss: 0.41847423630651803|ValidLoss: 0.44011838195490427|Iteration: 900\n",
      "Training|TrainLoss: 0.41611811075928706|Train1Loss: 0.41611811075928706|ValidLoss: 0.43698211531645914|Iteration: 1000\n",
      "Training|TrainLoss: 0.41388687149886216|Train1Loss: 0.41388687149886216|ValidLoss: 0.43401726645647315|Iteration: 1100\n",
      "Training|TrainLoss: 0.41185764695525273|Train1Loss: 0.41185764695525273|ValidLoss: 0.43143728613004034|Iteration: 1200\n",
      "Training|TrainLoss: 0.41012743514601785|Train1Loss: 0.41012743514601785|ValidLoss: 0.4289416045213596|Iteration: 1300\n",
      "Training|TrainLoss: 0.40858560130910404|Train1Loss: 0.40858560130910404|ValidLoss: 0.4269568241547141|Iteration: 1400\n",
      "Training|TrainLoss: 0.4071246965031705|Train1Loss: 0.4071246965031705|ValidLoss: 0.4249575346404773|Iteration: 1500\n",
      "Training|TrainLoss: 0.40572625032580606|Train1Loss: 0.40572625032580606|ValidLoss: 0.42293800169531737|Iteration: 1600\n",
      "Training|TrainLoss: 0.4044479367042634|Train1Loss: 0.4044479367042634|ValidLoss: 0.42104410770200656|Iteration: 1700\n",
      "Training|TrainLoss: 0.40326787947584963|Train1Loss: 0.40326787947584963|ValidLoss: 0.4189417513591354|Iteration: 1800\n",
      "Training|TrainLoss: 0.402159607113622|Train1Loss: 0.402159607113622|ValidLoss: 0.41691723508320333|Iteration: 1900\n",
      "Training|TrainLoss: 0.4010807740163936|Train1Loss: 0.4010807740163936|ValidLoss: 0.415047415891369|Iteration: 2000\n",
      "Training|TrainLoss: 0.4000531904763631|Train1Loss: 0.4000531904763631|ValidLoss: 0.4132287163890146|Iteration: 2100\n",
      "Training|TrainLoss: 0.3990158069114399|Train1Loss: 0.3990158069114399|ValidLoss: 0.4117545315240546|Iteration: 2200\n",
      "Training|TrainLoss: 0.3979862928905632|Train1Loss: 0.3979862928905632|ValidLoss: 0.41022515001065507|Iteration: 2300\n",
      "Training|TrainLoss: 0.3970251352691541|Train1Loss: 0.3970251352691541|ValidLoss: 0.4086314946691932|Iteration: 2400\n",
      "Training|TrainLoss: 0.396070402681178|Train1Loss: 0.396070402681178|ValidLoss: 0.4070763641010932|Iteration: 2500\n",
      "Training|TrainLoss: 0.39514403800923165|Train1Loss: 0.39514403800923165|ValidLoss: 0.40559071859662904|Iteration: 2600\n",
      "Training|TrainLoss: 0.3942718413693892|Train1Loss: 0.3942718413693892|ValidLoss: 0.40437118062992544|Iteration: 2700\n",
      "Training|TrainLoss: 0.39341710105201655|Train1Loss: 0.39341710105201655|ValidLoss: 0.4032321458495718|Iteration: 2800\n",
      "Training|TrainLoss: 0.3926521858426455|Train1Loss: 0.3926521858426455|ValidLoss: 0.4019284656409597|Iteration: 2900\n",
      "Training|TrainLoss: 0.39196245493662424|Train1Loss: 0.39196245493662424|ValidLoss: 0.4006573126230369|Iteration: 3000\n",
      "Training|TrainLoss: 0.3913255082078396|Train1Loss: 0.3913255082078396|ValidLoss: 0.3995206432142193|Iteration: 3100\n",
      "Training|TrainLoss: 0.3907116251039204|Train1Loss: 0.3907116251039204|ValidLoss: 0.398326552250754|Iteration: 3200\n",
      "Training|TrainLoss: 0.3901471377429433|Train1Loss: 0.3901471377429433|ValidLoss: 0.39703001897629026|Iteration: 3300\n",
      "Training|TrainLoss: 0.3895938660933947|Train1Loss: 0.3895938660933947|ValidLoss: 0.3957494398689252|Iteration: 3400\n",
      "Training|TrainLoss: 0.38909686846505287|Train1Loss: 0.38909686846505287|ValidLoss: 0.3945673662397002|Iteration: 3500\n",
      "Training|TrainLoss: 0.3886013682947875|Train1Loss: 0.3886013682947875|ValidLoss: 0.3934789705316321|Iteration: 3600\n",
      "Training|TrainLoss: 0.38811713770774425|Train1Loss: 0.38811713770774425|ValidLoss: 0.39261364171319313|Iteration: 3700\n",
      "Training|TrainLoss: 0.3876377246491856|Train1Loss: 0.3876377246491856|ValidLoss: 0.3918550853221494|Iteration: 3800\n",
      "Training|TrainLoss: 0.3871463683100159|Train1Loss: 0.3871463683100159|ValidLoss: 0.39091023835208333|Iteration: 3900\n",
      "Training|TrainLoss: 0.38671523308215344|Train1Loss: 0.38671523308215344|ValidLoss: 0.390035320227819|Iteration: 4000\n",
      "Training|TrainLoss: 0.38628835880794127|Train1Loss: 0.38628835880794127|ValidLoss: 0.38909589917897147|Iteration: 4100\n",
      "Training|TrainLoss: 0.3858733692446228|Train1Loss: 0.3858733692446228|ValidLoss: 0.3881381958984888|Iteration: 4200\n",
      "Training|TrainLoss: 0.38549169119380056|Train1Loss: 0.38549169119380056|ValidLoss: 0.38723844144009484|Iteration: 4300\n",
      "Training|TrainLoss: 0.3851372603458719|Train1Loss: 0.3851372603458719|ValidLoss: 0.38646269874703293|Iteration: 4400\n",
      "Training|TrainLoss: 0.3847528373488325|Train1Loss: 0.3847528373488325|ValidLoss: 0.38569435414065145|Iteration: 4500\n",
      "Training|TrainLoss: 0.38428853459974044|Train1Loss: 0.38428853459974044|ValidLoss: 0.3848547236635213|Iteration: 4600\n",
      "Training|TrainLoss: 0.3837842036657087|Train1Loss: 0.3837842036657087|ValidLoss: 0.38406133780980617|Iteration: 4700\n",
      "Training|TrainLoss: 0.3832840512386311|Train1Loss: 0.3832840512386311|ValidLoss: 0.3834936256707852|Iteration: 4800\n",
      "Training|TrainLoss: 0.382809931516524|Train1Loss: 0.382809931516524|ValidLoss: 0.383200391295924|Iteration: 4900\n",
      "Training|TrainLoss: 0.38235397494558276|Train1Loss: 0.38235397494558276|ValidLoss: 0.3828666496018107|Iteration: 5000\n",
      "Training|TrainLoss: 0.3819118911837608|Train1Loss: 0.3819118911837608|ValidLoss: 0.38226898034521445|Iteration: 5100\n",
      "Training|TrainLoss: 0.38146090445292896|Train1Loss: 0.38146090445292896|ValidLoss: 0.3816844299879557|Iteration: 5200\n",
      "Training|TrainLoss: 0.38100800939414087|Train1Loss: 0.38100800939414087|ValidLoss: 0.3810951025850357|Iteration: 5300\n",
      "Training|TrainLoss: 0.38053608637145514|Train1Loss: 0.38053608637145514|ValidLoss: 0.3805101674641305|Iteration: 5400\n",
      "Training|TrainLoss: 0.38006488207992833|Train1Loss: 0.38006488207992833|ValidLoss: 0.37979680016154005|Iteration: 5500\n",
      "Training|TrainLoss: 0.3795703098467152|Train1Loss: 0.3795703098467152|ValidLoss: 0.3791300332299746|Iteration: 5600\n",
      "Training|TrainLoss: 0.37911948651275323|Train1Loss: 0.37911948651275323|ValidLoss: 0.37846215088283397|Iteration: 5700\n",
      "Training|TrainLoss: 0.37865021798459025|Train1Loss: 0.37865021798459025|ValidLoss: 0.3777760835041233|Iteration: 5800\n",
      "Training|TrainLoss: 0.3781929693934517|Train1Loss: 0.3781929693934517|ValidLoss: 0.37712805425197177|Iteration: 5900\n",
      "Training|TrainLoss: 0.37776084103339685|Train1Loss: 0.37776084103339685|ValidLoss: 0.3764911967354928|Iteration: 6000\n",
      "Training|TrainLoss: 0.3772975535215407|Train1Loss: 0.3772975535215407|ValidLoss: 0.3759003664470462|Iteration: 6100\n",
      "Training|TrainLoss: 0.37684890063294946|Train1Loss: 0.37684890063294946|ValidLoss: 0.3754290874063237|Iteration: 6200\n",
      "Training|TrainLoss: 0.37641797545389794|Train1Loss: 0.37641797545389794|ValidLoss: 0.37507364267320215|Iteration: 6300\n",
      "Training|TrainLoss: 0.3760188265396124|Train1Loss: 0.3760188265396124|ValidLoss: 0.37488807859763973|Iteration: 6400\n",
      "Training|TrainLoss: 0.3756027916165438|Train1Loss: 0.3756027916165438|ValidLoss: 0.37467064613651596|Iteration: 6500\n",
      "Training|TrainLoss: 0.3751955265492001|Train1Loss: 0.3751955265492001|ValidLoss: 0.37436730946350344|Iteration: 6600\n",
      "Training|TrainLoss: 0.3748171453715106|Train1Loss: 0.3748171453715106|ValidLoss: 0.3740790364655081|Iteration: 6700\n",
      "Training|TrainLoss: 0.37445227127381486|Train1Loss: 0.37445227127381486|ValidLoss: 0.3737043300474574|Iteration: 6800\n",
      "Training|TrainLoss: 0.3740872517137558|Train1Loss: 0.3740872517137558|ValidLoss: 0.37330986476681355|Iteration: 6900\n",
      "Training|TrainLoss: 0.37374755433699064|Train1Loss: 0.37374755433699064|ValidLoss: 0.3729886124974631|Iteration: 7000\n",
      "Training|TrainLoss: 0.3734164124747788|Train1Loss: 0.3734164124747788|ValidLoss: 0.37272724291265125|Iteration: 7100\n",
      "Training|TrainLoss: 0.3730695044986082|Train1Loss: 0.3730695044986082|ValidLoss: 0.3724630901816679|Iteration: 7200\n",
      "Training|TrainLoss: 0.37273415439373|Train1Loss: 0.37273415439373|ValidLoss: 0.3722170720302649|Iteration: 7300\n",
      "Training|TrainLoss: 0.37240635832768987|Train1Loss: 0.37240635832768987|ValidLoss: 0.37204856679009113|Iteration: 7400\n",
      "Training|TrainLoss: 0.37205309566819833|Train1Loss: 0.37205309566819833|ValidLoss: 0.3718884495788125|Iteration: 7500\n",
      "Training|TrainLoss: 0.3716896736035983|Train1Loss: 0.3716896736035983|ValidLoss: 0.37172278197012876|Iteration: 7600\n",
      "Training|TrainLoss: 0.3713305808783869|Train1Loss: 0.3713305808783869|ValidLoss: 0.37158954976192543|Iteration: 7700\n",
      "Training|TrainLoss: 0.37098954801654543|Train1Loss: 0.37098954801654543|ValidLoss: 0.3714352485340006|Iteration: 7800\n",
      "Training|TrainLoss: 0.3706434281328532|Train1Loss: 0.3706434281328532|ValidLoss: 0.3711831302369367|Iteration: 7900\n",
      "Training|TrainLoss: 0.37029811483898023|Train1Loss: 0.37029811483898023|ValidLoss: 0.37091923840035146|Iteration: 8000\n",
      "Training|TrainLoss: 0.36994439750024427|Train1Loss: 0.36994439750024427|ValidLoss: 0.3707465946632676|Iteration: 8100\n",
      "Training|TrainLoss: 0.36959771104766004|Train1Loss: 0.36959771104766004|ValidLoss: 0.37069273244689344|Iteration: 8200\n",
      "Training|TrainLoss: 0.36927058165358145|Train1Loss: 0.36927058165358145|ValidLoss: 0.370695146279907|Iteration: 8300\n",
      "Training|TrainLoss: 0.3689271148813521|Train1Loss: 0.3689271148813521|ValidLoss: 0.3707460201479112|Iteration: 8400\n",
      "Training|TrainLoss: 0.36859735093107554|Train1Loss: 0.36859735093107554|ValidLoss: 0.37077786472534247|Iteration: 8500\n",
      "Training|TrainLoss: 0.3682940799212763|Train1Loss: 0.3682940799212763|ValidLoss: 0.37073964915408125|Iteration: 8600\n",
      "Training|TrainLoss: 0.367985283316804|Train1Loss: 0.367985283316804|ValidLoss: 0.37088066098777206|Iteration: 8700\n",
      "Training|TrainLoss: 0.3677011637418069|Train1Loss: 0.3677011637418069|ValidLoss: 0.370952791600649|Iteration: 8800\n",
      "Training|TrainLoss: 0.3674326135404744|Train1Loss: 0.3674326135404744|ValidLoss: 0.370944983682094|Iteration: 8900\n",
      "Training|TrainLoss: 0.36715661206440037|Train1Loss: 0.36715661206440037|ValidLoss: 0.371155921582531|Iteration: 9000\n",
      "Training|TrainLoss: 0.36689650834704857|Train1Loss: 0.36689650834704857|ValidLoss: 0.37128495286980623|Iteration: 9100\n",
      "Training|TrainLoss: 0.36663046657632103|Train1Loss: 0.36663046657632103|ValidLoss: 0.37145183766949874|Iteration: 9200\n",
      "Training|TrainLoss: 0.3663708027919209|Train1Loss: 0.3663708027919209|ValidLoss: 0.37157544580413604|Iteration: 9300\n",
      "Training|TrainLoss: 0.3661352250259031|Train1Loss: 0.3661352250259031|ValidLoss: 0.3716267171060958|Iteration: 9400\n",
      "Training|TrainLoss: 0.365902094242196|Train1Loss: 0.365902094242196|ValidLoss: 0.3716310780682768|Iteration: 9500\n",
      "Training|TrainLoss: 0.3656789979044217|Train1Loss: 0.3656789979044217|ValidLoss: 0.37158104280788695|Iteration: 9600\n",
      "Training|TrainLoss: 0.36545087148383515|Train1Loss: 0.36545087148383515|ValidLoss: 0.3716701415786048|Iteration: 9700\n",
      "Training|TrainLoss: 0.36525330432672376|Train1Loss: 0.36525330432672376|ValidLoss: 0.3716416653070373|Iteration: 9800\n",
      "Training|TrainLoss: 0.36493009263962917|Train1Loss: 0.36493009263962917|ValidLoss: 0.371613275978614|Iteration: 9900\n",
      "Training|TrainLoss: 0.3646037756513524|Train1Loss: 0.3646037756513524|ValidLoss: 0.37159771485930343|Iteration: 10000\n",
      "Training|TrainLoss: 0.36430302661724384|Train1Loss: 0.36430302661724384|ValidLoss: 0.37151496922381694|Iteration: 10100\n",
      "Training|TrainLoss: 0.36400571442347285|Train1Loss: 0.36400571442347285|ValidLoss: 0.3715500606209023|Iteration: 10200\n",
      "Training|TrainLoss: 0.36369813276836455|Train1Loss: 0.36369813276836455|ValidLoss: 0.3714488676501781|Iteration: 10300\n",
      "Training|TrainLoss: 0.36340864422597824|Train1Loss: 0.36340864422597824|ValidLoss: 0.3715270641369795|Iteration: 10400\n",
      "Training|TrainLoss: 0.36311951552276134|Train1Loss: 0.36311951552276134|ValidLoss: 0.3715045850682686|Iteration: 10500\n",
      "Training|TrainLoss: 0.3628294905814451|Train1Loss: 0.3628294905814451|ValidLoss: 0.37140913862521985|Iteration: 10600\n",
      "Training|TrainLoss: 0.36255479254099904|Train1Loss: 0.36255479254099904|ValidLoss: 0.3713823316159173|Iteration: 10700\n",
      "Training|TrainLoss: 0.3622843008397507|Train1Loss: 0.3622843008397507|ValidLoss: 0.3712289721782651|Iteration: 10800\n",
      "Training|TrainLoss: 0.36200460906483484|Train1Loss: 0.36200460906483484|ValidLoss: 0.371267803177989|Iteration: 10900\n",
      "Training|TrainLoss: 0.36173248819736414|Train1Loss: 0.36173248819736414|ValidLoss: 0.37129914860288177|Iteration: 11000\n",
      "Training|TrainLoss: 0.3614470426195362|Train1Loss: 0.3614470426195362|ValidLoss: 0.37134829165569533|Iteration: 11100\n",
      "Training|TrainLoss: 0.36113783108093034|Train1Loss: 0.36113783108093034|ValidLoss: 0.37132668777691535|Iteration: 11200\n",
      "Training|TrainLoss: 0.3608311342697539|Train1Loss: 0.3608311342697539|ValidLoss: 0.3712258221603157|Iteration: 11300\n",
      "Training|TrainLoss: 0.36055407491290864|Train1Loss: 0.36055407491290864|ValidLoss: 0.3711191817484263|Iteration: 11400\n",
      "Training|TrainLoss: 0.3602750309554344|Train1Loss: 0.3602750309554344|ValidLoss: 0.3712782449798433|Iteration: 11500\n",
      "Training|TrainLoss: 0.36000706435311813|Train1Loss: 0.36000706435311813|ValidLoss: 0.37128312411483866|Iteration: 11600\n",
      "Training|TrainLoss: 0.3597322946419828|Train1Loss: 0.3597322946419828|ValidLoss: 0.3713571199018668|Iteration: 11700\n",
      "Training|TrainLoss: 0.3594316567146204|Train1Loss: 0.3594316567146204|ValidLoss: 0.3714474505142881|Iteration: 11800\n",
      "Training|TrainLoss: 0.35910618722978727|Train1Loss: 0.35910618722978727|ValidLoss: 0.37162204341718724|Iteration: 11900\n",
      "Training|TrainLoss: 0.3588039445173352|Train1Loss: 0.3588039445173352|ValidLoss: 0.37180173043880904|Iteration: 12000\n",
      "Training|TrainLoss: 0.35850845327817554|Train1Loss: 0.35850845327817554|ValidLoss: 0.37180803263216744|Iteration: 12100\n",
      "Training|TrainLoss: 0.3581983594540873|Train1Loss: 0.3581983594540873|ValidLoss: 0.3718304954845835|Iteration: 12200\n",
      "Training|TrainLoss: 0.35791362496146384|Train1Loss: 0.35791362496146384|ValidLoss: 0.372066674113336|Iteration: 12300\n",
      "Training|TrainLoss: 0.357635661268272|Train1Loss: 0.357635661268272|ValidLoss: 0.37247765862256904|Iteration: 12400\n",
      "Training|TrainLoss: 0.3573639194399214|Train1Loss: 0.3573639194399214|ValidLoss: 0.37292634057595075|Iteration: 12500\n",
      "Training|TrainLoss: 0.3571099506220523|Train1Loss: 0.3571099506220523|ValidLoss: 0.37352288281176693|Iteration: 12600\n",
      "Training|TrainLoss: 0.3568615429213787|Train1Loss: 0.3568615429213787|ValidLoss: 0.37373493524266177|Iteration: 12700\n",
      "Training|TrainLoss: 0.3566041571818217|Train1Loss: 0.3566041571818217|ValidLoss: 0.3743355537613651|Iteration: 12800\n",
      "Training|TrainLoss: 0.3563649434811061|Train1Loss: 0.3563649434811061|ValidLoss: 0.37479788019711974|Iteration: 12900\n",
      "Training|TrainLoss: 0.35611302467439293|Train1Loss: 0.35611302467439293|ValidLoss: 0.37546563062167376|Iteration: 13000\n",
      "Training|TrainLoss: 0.3558901365573586|Train1Loss: 0.3558901365573586|ValidLoss: 0.3757265164174113|Iteration: 13100\n",
      "Training|TrainLoss: 0.3556676177093195|Train1Loss: 0.3556676177093195|ValidLoss: 0.3761491092255447|Iteration: 13200\n",
      "Training|TrainLoss: 0.3554539651709608|Train1Loss: 0.3554539651709608|ValidLoss: 0.37653862040102953|Iteration: 13300\n",
      "Training|TrainLoss: 0.35513363775024415|Train1Loss: 0.35513363775024415|ValidLoss: 0.37728029316916306|Iteration: 13400\n",
      "Training|TrainLoss: 0.3548465189894936|Train1Loss: 0.3548465189894936|ValidLoss: 0.37784974005603345|Iteration: 13500\n",
      "Training|TrainLoss: 0.35457261837885484|Train1Loss: 0.35457261837885484|ValidLoss: 0.37832855511091396|Iteration: 13600\n",
      "Training|TrainLoss: 0.35430558697115494|Train1Loss: 0.35430558697115494|ValidLoss: 0.3790572777648153|Iteration: 13700\n",
      "Training|TrainLoss: 0.35407244324442005|Train1Loss: 0.35407244324442005|ValidLoss: 0.3793799375786528|Iteration: 13800\n",
      "Training|TrainLoss: 0.3538356536787786|Train1Loss: 0.3538356536787786|ValidLoss: 0.379843438736789|Iteration: 13900\n",
      "Training|TrainLoss: 0.35361960439240114|Train1Loss: 0.35361960439240114|ValidLoss: 0.380296132691906|Iteration: 14000\n",
      "Training|TrainLoss: 0.35341246116120767|Train1Loss: 0.35341246116120767|ValidLoss: 0.3806761558514842|Iteration: 14100\n",
      "Training|TrainLoss: 0.3531789047127782|Train1Loss: 0.3531789047127782|ValidLoss: 0.38128242485183766|Iteration: 14200\n",
      "Training|TrainLoss: 0.3529577538177624|Train1Loss: 0.3529577538177624|ValidLoss: 0.3818823396342756|Iteration: 14300\n",
      "Training|TrainLoss: 0.3527425749185028|Train1Loss: 0.3527425749185028|ValidLoss: 0.38258972627658644|Iteration: 14400\n",
      "Training|TrainLoss: 0.35256121075051583|Train1Loss: 0.35256121075051583|ValidLoss: 0.38292542984719846|Iteration: 14500\n",
      "Training|TrainLoss: 0.35234154418708225|Train1Loss: 0.35234154418708225|ValidLoss: 0.3832685935565324|Iteration: 14600\n",
      "Training|TrainLoss: 0.3521401720159469|Train1Loss: 0.3521401720159469|ValidLoss: 0.38394067196840803|Iteration: 14700\n",
      "Training|TrainLoss: 0.3519905090686244|Train1Loss: 0.3519905090686244|ValidLoss: 0.38437539548294875|Iteration: 14800\n",
      "Training|TrainLoss: 0.35183356199850985|Train1Loss: 0.35183356199850985|ValidLoss: 0.3849647505562743|Iteration: 14900\n",
      "Training|TrainLoss: 0.35169672255601386|Train1Loss: 0.35169672255601386|ValidLoss: 0.3853126012932011|Iteration: 15000\n",
      "Training|TrainLoss: 0.35157566704546267|Train1Loss: 0.35157566704546267|ValidLoss: 0.3853906805799297|Iteration: 15100\n",
      "Training|TrainLoss: 0.35146240310253224|Train1Loss: 0.35146240310253224|ValidLoss: 0.38561527397040496|Iteration: 15200\n",
      "Training|TrainLoss: 0.3513597890525864|Train1Loss: 0.3513597890525864|ValidLoss: 0.3858521868381068|Iteration: 15300\n",
      "Training|TrainLoss: 0.3512323687424791|Train1Loss: 0.3512323687424791|ValidLoss: 0.38630710927459033|Iteration: 15400\n",
      "Training|TrainLoss: 0.3511332419384922|Train1Loss: 0.3511332419384922|ValidLoss: 0.38653670965831166|Iteration: 15500\n",
      "Training|TrainLoss: 0.3510342988892697|Train1Loss: 0.3510342988892697|ValidLoss: 0.38675097222451243|Iteration: 15600\n",
      "Training|TrainLoss: 0.35094358028120437|Train1Loss: 0.35094358028120437|ValidLoss: 0.3868734320880387|Iteration: 15700\n",
      "Training|TrainLoss: 0.3508526679438667|Train1Loss: 0.3508526679438667|ValidLoss: 0.3871993293381364|Iteration: 15800\n",
      "Training|TrainLoss: 0.35077235834002146|Train1Loss: 0.35077235834002146|ValidLoss: 0.3873780465549094|Iteration: 15900\n",
      "Training|TrainLoss: 0.35068934847618577|Train1Loss: 0.35068934847618577|ValidLoss: 0.38760470315333995|Iteration: 16000\n",
      "Training|TrainLoss: 0.35060994691721203|Train1Loss: 0.35060994691721203|ValidLoss: 0.38778883075211623|Iteration: 16100\n",
      "Training|TrainLoss: 0.35053241135531765|Train1Loss: 0.35053241135531765|ValidLoss: 0.38772100503322243|Iteration: 16200\n",
      "Training|TrainLoss: 0.35042850570223194|Train1Loss: 0.35042850570223194|ValidLoss: 0.3880934802213168|Iteration: 16300\n",
      "Training|TrainLoss: 0.35034496944256005|Train1Loss: 0.35034496944256005|ValidLoss: 0.38766824234027375|Iteration: 16400\n",
      "Training|TrainLoss: 0.35025333169868206|Train1Loss: 0.35025333169868206|ValidLoss: 0.3874156876475411|Iteration: 16500\n",
      "Training|TrainLoss: 0.3501417599831507|Train1Loss: 0.3501417599831507|ValidLoss: 0.38748409381206983|Iteration: 16600\n",
      "Training|TrainLoss: 0.3500655085880392|Train1Loss: 0.3500655085880392|ValidLoss: 0.38712818650310266|Iteration: 16700\n",
      "Training|TrainLoss: 0.3499758034492803|Train1Loss: 0.3499758034492803|ValidLoss: 0.3868884961056514|Iteration: 16800\n",
      "Training|TrainLoss: 0.3498584964382399|Train1Loss: 0.3498584964382399|ValidLoss: 0.38694100448744684|Iteration: 16900\n",
      "Training|TrainLoss: 0.3497594766669348|Train1Loss: 0.3497594766669348|ValidLoss: 0.38676038884226904|Iteration: 17000\n",
      "Training|TrainLoss: 0.3496607716098143|Train1Loss: 0.3496607716098143|ValidLoss: 0.38667630514844176|Iteration: 17100\n",
      "Training|TrainLoss: 0.3495871298753795|Train1Loss: 0.3495871298753795|ValidLoss: 0.3864469875272426|Iteration: 17200\n",
      "Training|TrainLoss: 0.34948883138415454|Train1Loss: 0.34948883138415454|ValidLoss: 0.3865893926240706|Iteration: 17300\n",
      "Training|TrainLoss: 0.3493946895101591|Train1Loss: 0.3493946895101591|ValidLoss: 0.3864619172203697|Iteration: 17400\n",
      "Training|TrainLoss: 0.34929589075406353|Train1Loss: 0.34929589075406353|ValidLoss: 0.3860122165718572|Iteration: 17500\n",
      "Training|TrainLoss: 0.3491674020542399|Train1Loss: 0.3491674020542399|ValidLoss: 0.3860397647475937|Iteration: 17600\n",
      "Training|TrainLoss: 0.34904477979545445|Train1Loss: 0.34904477979545445|ValidLoss: 0.38573087960582253|Iteration: 17700\n",
      "Training|TrainLoss: 0.34893868650812077|Train1Loss: 0.34893868650812077|ValidLoss: 0.38527750045439735|Iteration: 17800\n",
      "Training|TrainLoss: 0.34881501356342226|Train1Loss: 0.34881501356342226|ValidLoss: 0.3852935439127194|Iteration: 17900\n",
      "Training|TrainLoss: 0.3487089981530531|Train1Loss: 0.3487089981530531|ValidLoss: 0.3849524541240411|Iteration: 18000\n",
      "Training|TrainLoss: 0.34863484663365|Train1Loss: 0.34863484663365|ValidLoss: 0.384360309991323|Iteration: 18100\n",
      "Training|TrainLoss: 0.3485389849863211|Train1Loss: 0.3485389849863211|ValidLoss: 0.3841313804801376|Iteration: 18200\n",
      "Training|TrainLoss: 0.3484628182151907|Train1Loss: 0.3484628182151907|ValidLoss: 0.38382411099802105|Iteration: 18300\n",
      "Training|TrainLoss: 0.34837907946499364|Train1Loss: 0.34837907946499364|ValidLoss: 0.3833960995924869|Iteration: 18400\n",
      "Training|TrainLoss: 0.348303082379098|Train1Loss: 0.348303082379098|ValidLoss: 0.3829259137534827|Iteration: 18500\n",
      "Training|TrainLoss: 0.34821313039349605|Train1Loss: 0.34821313039349605|ValidLoss: 0.38288678483918515|Iteration: 18600\n",
      "Training|TrainLoss: 0.3481408121191215|Train1Loss: 0.3481408121191215|ValidLoss: 0.3825948171290824|Iteration: 18700\n",
      "Training|TrainLoss: 0.34805323103696945|Train1Loss: 0.34805323103696945|ValidLoss: 0.3826263622156402|Iteration: 18800\n",
      "Training|TrainLoss: 0.3479857714336738|Train1Loss: 0.3479857714336738|ValidLoss: 0.382371200376902|Iteration: 18900\n",
      "Training|TrainLoss: 0.3479084189757451|Train1Loss: 0.3479084189757451|ValidLoss: 0.3824995502810613|Iteration: 19000\n",
      "Training|TrainLoss: 0.34783410448414964|Train1Loss: 0.34783410448414964|ValidLoss: 0.38227627861882074|Iteration: 19100\n",
      "Training|TrainLoss: 0.34776921201685473|Train1Loss: 0.34776921201685473|ValidLoss: 0.38213734415191764|Iteration: 19200\n",
      "Training|TrainLoss: 0.34770204363994095|Train1Loss: 0.34770204363994095|ValidLoss: 0.38213774422848407|Iteration: 19300\n",
      "Training|TrainLoss: 0.3476456001466316|Train1Loss: 0.3476456001466316|ValidLoss: 0.3821085992977614|Iteration: 19400\n",
      "Training|TrainLoss: 0.3476073410588994|Train1Loss: 0.3476073410588994|ValidLoss: 0.38181851751706264|Iteration: 19500\n",
      "Training|TrainLoss: 0.34753426479911753|Train1Loss: 0.34753426479911753|ValidLoss: 0.3820444827610462|Iteration: 19600\n",
      "Training|TrainLoss: 0.3474632762304672|Train1Loss: 0.3474632762304672|ValidLoss: 0.38188798186287787|Iteration: 19700\n",
      "Training|TrainLoss: 0.3474060648580628|Train1Loss: 0.3474060648580628|ValidLoss: 0.38186094613982113|Iteration: 19800\n",
      "Training|TrainLoss: 0.34734351550867865|Train1Loss: 0.34734351550867865|ValidLoss: 0.38179786689535583|Iteration: 19900\n",
      "Training|TrainLoss: 0.34728445390531815|Train1Loss: 0.34728445390531815|ValidLoss: 0.38183593926193776|Iteration: 20000\n",
      "Training|TrainLoss: 0.34716067578818355|Train1Loss: 0.34716067578818355|ValidLoss: 0.3817869405607223|Iteration: 20100\n",
      "Training|TrainLoss: 0.3470226016401861|Train1Loss: 0.3470226016401861|ValidLoss: 0.3820834898460699|Iteration: 20200\n",
      "Training|TrainLoss: 0.3469210426703049|Train1Loss: 0.3469210426703049|ValidLoss: 0.38230285972824846|Iteration: 20300\n",
      "Training|TrainLoss: 0.3468131051230455|Train1Loss: 0.3468131051230455|ValidLoss: 0.3825398329517287|Iteration: 20400\n",
      "Training|TrainLoss: 0.34671335358423105|Train1Loss: 0.34671335358423105|ValidLoss: 0.3826891424967763|Iteration: 20500\n",
      "Training|TrainLoss: 0.34661705696964334|Train1Loss: 0.34661705696964334|ValidLoss: 0.38281064465432024|Iteration: 20600\n",
      "Training|TrainLoss: 0.346526490758839|Train1Loss: 0.346526490758839|ValidLoss: 0.38281741336214364|Iteration: 20700\n",
      "Training|TrainLoss: 0.346431043531204|Train1Loss: 0.346431043531204|ValidLoss: 0.3828754677985497|Iteration: 20800\n",
      "Training|TrainLoss: 0.3463476522755276|Train1Loss: 0.3463476522755276|ValidLoss: 0.3830808416289756|Iteration: 20900\n",
      "Training|TrainLoss: 0.34626360431103825|Train1Loss: 0.34626360431103825|ValidLoss: 0.38307269532882443|Iteration: 21000\n",
      "Training|TrainLoss: 0.3461871671510508|Train1Loss: 0.3461871671510508|ValidLoss: 0.38300152343884664|Iteration: 21100\n",
      "Training|TrainLoss: 0.346099710368936|Train1Loss: 0.346099710368936|ValidLoss: 0.38304066565496275|Iteration: 21200\n",
      "Training|TrainLoss: 0.34599975022576684|Train1Loss: 0.34599975022576684|ValidLoss: 0.3830724306978765|Iteration: 21300\n",
      "Training|TrainLoss: 0.34589884129263093|Train1Loss: 0.34589884129263093|ValidLoss: 0.38271182747459687|Iteration: 21400\n",
      "Training|TrainLoss: 0.34570614307451264|Train1Loss: 0.34570614307451264|ValidLoss: 0.38252322185650056|Iteration: 21500\n",
      "Training|TrainLoss: 0.34552409348725194|Train1Loss: 0.34552409348725194|ValidLoss: 0.38222744817515014|Iteration: 21600\n",
      "Training|TrainLoss: 0.34534841296761926|Train1Loss: 0.34534841296761926|ValidLoss: 0.38200132310682333|Iteration: 21700\n",
      "Training|TrainLoss: 0.3451758482943124|Train1Loss: 0.3451758482943124|ValidLoss: 0.3817429571786139|Iteration: 21800\n",
      "Training|TrainLoss: 0.3449987268815153|Train1Loss: 0.3449987268815153|ValidLoss: 0.3815282624302453|Iteration: 21900\n",
      "Training|TrainLoss: 0.34481796687530997|Train1Loss: 0.34481796687530997|ValidLoss: 0.3814275521017967|Iteration: 22000\n",
      "Training|TrainLoss: 0.3446560212878433|Train1Loss: 0.3446560212878433|ValidLoss: 0.38134021675924223|Iteration: 22100\n",
      "Training|TrainLoss: 0.3445155512536985|Train1Loss: 0.3445155512536985|ValidLoss: 0.3812302064083032|Iteration: 22200\n",
      "Training|TrainLoss: 0.3443697687933499|Train1Loss: 0.3443697687933499|ValidLoss: 0.38109237406341817|Iteration: 22300\n",
      "Training|TrainLoss: 0.34422640173105934|Train1Loss: 0.34422640173105934|ValidLoss: 0.3809505182938515|Iteration: 22400\n",
      "Training|TrainLoss: 0.34410017589301106|Train1Loss: 0.34410017589301106|ValidLoss: 0.380822303619815|Iteration: 22500\n",
      "Training|TrainLoss: 0.3439801650335142|Train1Loss: 0.3439801650335142|ValidLoss: 0.38055400576919285|Iteration: 22600\n",
      "Training|TrainLoss: 0.34384500748713265|Train1Loss: 0.34384500748713265|ValidLoss: 0.38063080063790905|Iteration: 22700\n",
      "Training|TrainLoss: 0.34370998354515664|Train1Loss: 0.34370998354515664|ValidLoss: 0.3807330043525768|Iteration: 22800\n",
      "Training|TrainLoss: 0.34360283755161475|Train1Loss: 0.34360283755161475|ValidLoss: 0.3806822289976954|Iteration: 22900\n",
      "Training|TrainLoss: 0.3434949354897381|Train1Loss: 0.3434949354897381|ValidLoss: 0.38060472062772843|Iteration: 23000\n",
      "Training|TrainLoss: 0.34339456033545046|Train1Loss: 0.34339456033545046|ValidLoss: 0.3804416851564982|Iteration: 23100\n",
      "Training|TrainLoss: 0.3432715443410553|Train1Loss: 0.3432715443410553|ValidLoss: 0.3805942617776058|Iteration: 23200\n",
      "Training|TrainLoss: 0.34315545909466166|Train1Loss: 0.34315545909466166|ValidLoss: 0.38048505338650734|Iteration: 23300\n",
      "Training|TrainLoss: 0.3430326464382404|Train1Loss: 0.3430326464382404|ValidLoss: 0.3803144931775175|Iteration: 23400\n",
      "Training|TrainLoss: 0.3429229399144738|Train1Loss: 0.3429229399144738|ValidLoss: 0.38031541368417093|Iteration: 23500\n",
      "Training|TrainLoss: 0.34277349550036446|Train1Loss: 0.34277349550036446|ValidLoss: 0.3804564130049276|Iteration: 23600\n",
      "Training|TrainLoss: 0.34263719998200237|Train1Loss: 0.34263719998200237|ValidLoss: 0.3804457077825056|Iteration: 23700\n",
      "Training|TrainLoss: 0.34248002259538085|Train1Loss: 0.34248002259538085|ValidLoss: 0.38067059332765535|Iteration: 23800\n",
      "Training|TrainLoss: 0.3422468894322077|Train1Loss: 0.3422468894322077|ValidLoss: 0.38084157012017106|Iteration: 23900\n",
      "Training|TrainLoss: 0.3420169241226057|Train1Loss: 0.3420169241226057|ValidLoss: 0.38133350217680784|Iteration: 24000\n",
      "Training|TrainLoss: 0.3418639844821138|Train1Loss: 0.3418639844821138|ValidLoss: 0.3811847073949645|Iteration: 24100\n",
      "Training|TrainLoss: 0.3416979039456541|Train1Loss: 0.3416979039456541|ValidLoss: 0.38122262934755474|Iteration: 24200\n",
      "Training|TrainLoss: 0.3415569519599336|Train1Loss: 0.3415569519599336|ValidLoss: 0.38122654528861594|Iteration: 24300\n",
      "Training|TrainLoss: 0.3414040393981674|Train1Loss: 0.3414040393981674|ValidLoss: 0.3811713083207907|Iteration: 24400\n",
      "Training|TrainLoss: 0.34121193860442417|Train1Loss: 0.34121193860442417|ValidLoss: 0.381131511128965|Iteration: 24500\n",
      "Training|TrainLoss: 0.34103461721686756|Train1Loss: 0.34103461721686756|ValidLoss: 0.38123242685654435|Iteration: 24600\n",
      "Training|TrainLoss: 0.34087296155286323|Train1Loss: 0.34087296155286323|ValidLoss: 0.3811772554993025|Iteration: 24700\n",
      "Training|TrainLoss: 0.34072105166260586|Train1Loss: 0.34072105166260586|ValidLoss: 0.3808364191801226|Iteration: 24800\n",
      "Training|TrainLoss: 0.34057665830937645|Train1Loss: 0.34057665830937645|ValidLoss: 0.38107572347310337|Iteration: 24900\n",
      "Training|TrainLoss: 0.340423352341367|Train1Loss: 0.340423352341367|ValidLoss: 0.3810098291706446|Iteration: 25000\n",
      "Training|TrainLoss: 0.34027987405810656|Train1Loss: 0.34027987405810656|ValidLoss: 0.3808149800366281|Iteration: 25100\n",
      "Training|TrainLoss: 0.3401200366209489|Train1Loss: 0.3401200366209489|ValidLoss: 0.38068183681544027|Iteration: 25200\n",
      "Training|TrainLoss: 0.33999318750656543|Train1Loss: 0.33999318750656543|ValidLoss: 0.3801626974539015|Iteration: 25300\n",
      "Training|TrainLoss: 0.3398486099354509|Train1Loss: 0.3398486099354509|ValidLoss: 0.38004825576581874|Iteration: 25400\n",
      "Training|TrainLoss: 0.339732603532073|Train1Loss: 0.339732603532073|ValidLoss: 0.38004026186565687|Iteration: 25500\n",
      "Training|TrainLoss: 0.33963187191974675|Train1Loss: 0.33963187191974675|ValidLoss: 0.379719616540109|Iteration: 25600\n",
      "Training|TrainLoss: 0.33953347900300995|Train1Loss: 0.33953347900300995|ValidLoss: 0.37964497759602733|Iteration: 25700\n",
      "Training|TrainLoss: 0.3394437927743572|Train1Loss: 0.3394437927743572|ValidLoss: 0.37965441000774625|Iteration: 25800\n",
      "Training|TrainLoss: 0.3393555279170829|Train1Loss: 0.3393555279170829|ValidLoss: 0.3796729578742084|Iteration: 25900\n",
      "Training|TrainLoss: 0.3392564602674295|Train1Loss: 0.3392564602674295|ValidLoss: 0.37977071786533395|Iteration: 26000\n",
      "Training|TrainLoss: 0.33918256463355073|Train1Loss: 0.33918256463355073|ValidLoss: 0.37962842332732627|Iteration: 26100\n",
      "Training|TrainLoss: 0.33909325033236715|Train1Loss: 0.33909325033236715|ValidLoss: 0.3797166727682027|Iteration: 26200\n",
      "Training|TrainLoss: 0.33903854534253497|Train1Loss: 0.33903854534253497|ValidLoss: 0.3794151536399495|Iteration: 26300\n",
      "Training|TrainLoss: 0.33896413482850846|Train1Loss: 0.33896413482850846|ValidLoss: 0.3793610411099948|Iteration: 26400\n",
      "Training|TrainLoss: 0.338865789640935|Train1Loss: 0.338865789640935|ValidLoss: 0.3793341201577308|Iteration: 26500\n",
      "Training|TrainLoss: 0.3387994639942693|Train1Loss: 0.3387994639942693|ValidLoss: 0.37907871289047773|Iteration: 26600\n",
      "Training|TrainLoss: 0.3387074492853827|Train1Loss: 0.3387074492853827|ValidLoss: 0.37923742914631403|Iteration: 26700\n",
      "Training|TrainLoss: 0.33863542933510205|Train1Loss: 0.33863542933510205|ValidLoss: 0.3790914996315819|Iteration: 26800\n",
      "Training|TrainLoss: 0.33856282668652427|Train1Loss: 0.33856282668652427|ValidLoss: 0.37922667520002623|Iteration: 26900\n",
      "Training|TrainLoss: 0.3385095752495586|Train1Loss: 0.3385095752495586|ValidLoss: 0.3790298936744344|Iteration: 27000\n",
      "Training|TrainLoss: 0.3384416688668179|Train1Loss: 0.3384416688668179|ValidLoss: 0.3789805996150869|Iteration: 27100\n",
      "Training|TrainLoss: 0.3383752062917988|Train1Loss: 0.3383752062917988|ValidLoss: 0.37914344247225507|Iteration: 27200\n",
      "Training|TrainLoss: 0.3383004969208167|Train1Loss: 0.3383004969208167|ValidLoss: 0.3790990683676333|Iteration: 27300\n",
      "Training|TrainLoss: 0.3382098990711142|Train1Loss: 0.3382098990711142|ValidLoss: 0.37911614655322473|Iteration: 27400\n",
      "Training|TrainLoss: 0.33813036269797275|Train1Loss: 0.33813036269797275|ValidLoss: 0.3790080512225531|Iteration: 27500\n",
      "Training|TrainLoss: 0.338061082963512|Train1Loss: 0.338061082963512|ValidLoss: 0.37926373752028353|Iteration: 27600\n",
      "Training|TrainLoss: 0.33800411547495124|Train1Loss: 0.33800411547495124|ValidLoss: 0.37892023516483647|Iteration: 27700\n",
      "Training|TrainLoss: 0.3379262647656013|Train1Loss: 0.3379262647656013|ValidLoss: 0.37902618273354416|Iteration: 27800\n",
      "Training|TrainLoss: 0.3378640621211623|Train1Loss: 0.3378640621211623|ValidLoss: 0.3788679562796362|Iteration: 27900\n",
      "Training|TrainLoss: 0.33775832038595943|Train1Loss: 0.33775832038595943|ValidLoss: 0.37940472516449264|Iteration: 28000\n",
      "Training|TrainLoss: 0.33767182840088517|Train1Loss: 0.33767182840088517|ValidLoss: 0.37917795776809055|Iteration: 28100\n",
      "Training|TrainLoss: 0.3376056491694176|Train1Loss: 0.3376056491694176|ValidLoss: 0.37923978302073075|Iteration: 28200\n",
      "Training|TrainLoss: 0.33756398565690615|Train1Loss: 0.33756398565690615|ValidLoss: 0.378734964180281|Iteration: 28300\n",
      "Training|TrainLoss: 0.33746961527879626|Train1Loss: 0.33746961527879626|ValidLoss: 0.3790924500071916|Iteration: 28400\n",
      "Training|TrainLoss: 0.33741032912898306|Train1Loss: 0.33741032912898306|ValidLoss: 0.3790176223711012|Iteration: 28500\n",
      "Training|TrainLoss: 0.3373355674293323|Train1Loss: 0.3373355674293323|ValidLoss: 0.378734048549379|Iteration: 28600\n",
      "Training|TrainLoss: 0.3372799123610577|Train1Loss: 0.3372799123610577|ValidLoss: 0.37887946335739847|Iteration: 28700\n",
      "Training|TrainLoss: 0.337216510830858|Train1Loss: 0.337216510830858|ValidLoss: 0.37860524504155996|Iteration: 28800\n",
      "Training|TrainLoss: 0.337145137540403|Train1Loss: 0.337145137540403|ValidLoss: 0.37869932574552884|Iteration: 28900\n",
      "Training|TrainLoss: 0.3370827661449392|Train1Loss: 0.3370827661449392|ValidLoss: 0.37891697958467097|Iteration: 29000\n",
      "Training|TrainLoss: 0.33704063808011037|Train1Loss: 0.33704063808011037|ValidLoss: 0.3786868058881728|Iteration: 29100\n",
      "Training|TrainLoss: 0.3369580946097277|Train1Loss: 0.3369580946097277|ValidLoss: 0.3789108847181561|Iteration: 29200\n",
      "Training|TrainLoss: 0.3368866791762393|Train1Loss: 0.3368866791762393|ValidLoss: 0.3790623757679199|Iteration: 29300\n",
      "Training|TrainLoss: 0.33683655852798233|Train1Loss: 0.33683655852798233|ValidLoss: 0.3793624763477589|Iteration: 29400\n",
      "Training|TrainLoss: 0.33678707085414855|Train1Loss: 0.33678707085414855|ValidLoss: 0.3790031957491272|Iteration: 29500\n",
      "Training|TrainLoss: 0.33674161662749014|Train1Loss: 0.33674161662749014|ValidLoss: 0.37905874644039417|Iteration: 29600\n",
      "Training|TrainLoss: 0.3366855833738214|Train1Loss: 0.3366855833738214|ValidLoss: 0.37921419025309683|Iteration: 29700\n",
      "Training|TrainLoss: 0.33660798854367974|Train1Loss: 0.33660798854367974|ValidLoss: 0.37948546024832264|Iteration: 29800\n",
      "Training|TrainLoss: 0.3365642492864076|Train1Loss: 0.3365642492864076|ValidLoss: 0.37969366813374505|Iteration: 29900\n",
      "Training|TrainLoss: 0.33651019764558315|Train1Loss: 0.33651019764558315|ValidLoss: 0.379663791941989|Iteration: 30000\n",
      "Training|TrainLoss: 0.33645827677163426|Train1Loss: 0.33645827677163426|ValidLoss: 0.3796997324715358|Iteration: 30100\n",
      "Training|TrainLoss: 0.3364325747482049|Train1Loss: 0.3364325747482049|ValidLoss: 0.3797853793283167|Iteration: 30200\n",
      "Training|TrainLoss: 0.3363727626074063|Train1Loss: 0.3363727626074063|ValidLoss: 0.37986816012797353|Iteration: 30300\n",
      "Training|TrainLoss: 0.3363194188233519|Train1Loss: 0.3363194188233519|ValidLoss: 0.37991121964054414|Iteration: 30400\n",
      "Training|TrainLoss: 0.3362869857073241|Train1Loss: 0.3362869857073241|ValidLoss: 0.38001087121303956|Iteration: 30500\n",
      "Training|TrainLoss: 0.33623764307598514|Train1Loss: 0.33623764307598514|ValidLoss: 0.3798688233495805|Iteration: 30600\n",
      "Training|TrainLoss: 0.33619852006155176|Train1Loss: 0.33619852006155176|ValidLoss: 0.38011467662303133|Iteration: 30700\n",
      "Training|TrainLoss: 0.3361595553379847|Train1Loss: 0.3361595553379847|ValidLoss: 0.3801414199405313|Iteration: 30800\n",
      "Training|TrainLoss: 0.3361210964919905|Train1Loss: 0.3361210964919905|ValidLoss: 0.3800796253064688|Iteration: 30900\n",
      "Training|TrainLoss: 0.3360793349248018|Train1Loss: 0.3360793349248018|ValidLoss: 0.38012638581568636|Iteration: 31000\n",
      "Training|TrainLoss: 0.3360371731116221|Train1Loss: 0.3360371731116221|ValidLoss: 0.38010728156373735|Iteration: 31100\n",
      "Training|TrainLoss: 0.3360180710052092|Train1Loss: 0.3360180710052092|ValidLoss: 0.37966748897741337|Iteration: 31200\n",
      "Training|TrainLoss: 0.3359707867752541|Train1Loss: 0.3359707867752541|ValidLoss: 0.38007210460676305|Iteration: 31300\n",
      "Training|TrainLoss: 0.335925945142737|Train1Loss: 0.335925945142737|ValidLoss: 0.38005851726635675|Iteration: 31400\n",
      "Training|TrainLoss: 0.335881923064467|Train1Loss: 0.335881923064467|ValidLoss: 0.38007541711170373|Iteration: 31500\n",
      "Training|TrainLoss: 0.3358430010225234|Train1Loss: 0.3358430010225234|ValidLoss: 0.3798132137815771|Iteration: 31600\n",
      "Training|TrainLoss: 0.3358024458966288|Train1Loss: 0.3358024458966288|ValidLoss: 0.3799405787721571|Iteration: 31700\n",
      "Training|TrainLoss: 0.3357790185155618|Train1Loss: 0.3357790185155618|ValidLoss: 0.38019907314493745|Iteration: 31800\n",
      "Training|TrainLoss: 0.3357535058872938|Train1Loss: 0.3357535058872938|ValidLoss: 0.37977681176470957|Iteration: 31900\n",
      "Training|TrainLoss: 0.3357134907049891|Train1Loss: 0.3357134907049891|ValidLoss: 0.3796722715205712|Iteration: 32000\n",
      "Training|TrainLoss: 0.33567063768538086|Train1Loss: 0.33567063768538086|ValidLoss: 0.3796211460257406|Iteration: 32100\n",
      "Training|TrainLoss: 0.33561527119436685|Train1Loss: 0.33561527119436685|ValidLoss: 0.3799842822660499|Iteration: 32200\n",
      "Training|TrainLoss: 0.3355904525118487|Train1Loss: 0.3355904525118487|ValidLoss: 0.37951144434451556|Iteration: 32300\n",
      "Training|TrainLoss: 0.33553633245687087|Train1Loss: 0.33553633245687087|ValidLoss: 0.38001705984104284|Iteration: 32400\n",
      "Training|TrainLoss: 0.3354920379893421|Train1Loss: 0.3354920379893421|ValidLoss: 0.3800013619624991|Iteration: 32500\n",
      "Training|TrainLoss: 0.3354493721341457|Train1Loss: 0.3354493721341457|ValidLoss: 0.3799301895271824|Iteration: 32600\n",
      "Training|TrainLoss: 0.335417427262141|Train1Loss: 0.335417427262141|ValidLoss: 0.37976571365487133|Iteration: 32700\n",
      "Training|TrainLoss: 0.33538488104881736|Train1Loss: 0.33538488104881736|ValidLoss: 0.379903207879183|Iteration: 32800\n",
      "Training|TrainLoss: 0.33534448426729596|Train1Loss: 0.33534448426729596|ValidLoss: 0.37992773671448843|Iteration: 32900\n",
      "Training|TrainLoss: 0.33532280665585323|Train1Loss: 0.33532280665585323|ValidLoss: 0.3797158518697229|Iteration: 33000\n",
      "Training|TrainLoss: 0.33528741189953465|Train1Loss: 0.33528741189953465|ValidLoss: 0.3797953041810629|Iteration: 33100\n",
      "Training|TrainLoss: 0.33524764233914395|Train1Loss: 0.33524764233914395|ValidLoss: 0.37996561816290614|Iteration: 33200\n",
      "Training|TrainLoss: 0.3352256108282554|Train1Loss: 0.3352256108282554|ValidLoss: 0.3800045725774984|Iteration: 33300\n",
      "Training|TrainLoss: 0.33519683691799657|Train1Loss: 0.33519683691799657|ValidLoss: 0.3797299964467043|Iteration: 33400\n",
      "Training|TrainLoss: 0.3351828278695643|Train1Loss: 0.3351828278695643|ValidLoss: 0.37952685801739355|Iteration: 33500\n",
      "Training|TrainLoss: 0.3351366984472823|Train1Loss: 0.3351366984472823|ValidLoss: 0.37954640582322846|Iteration: 33600\n",
      "Training|TrainLoss: 0.33509686314499504|Train1Loss: 0.33509686314499504|ValidLoss: 0.37994446673898985|Iteration: 33700\n",
      "Training|TrainLoss: 0.33505773172562286|Train1Loss: 0.33505773172562286|ValidLoss: 0.37989879061285614|Iteration: 33800\n",
      "Training|TrainLoss: 0.33503148680021405|Train1Loss: 0.33503148680021405|ValidLoss: 0.3799059440621598|Iteration: 33900\n",
      "Training|TrainLoss: 0.3350106548728287|Train1Loss: 0.3350106548728287|ValidLoss: 0.37980141115438465|Iteration: 34000\n",
      "Training|TrainLoss: 0.3349724731193097|Train1Loss: 0.3349724731193097|ValidLoss: 0.3796392960236432|Iteration: 34100\n",
      "Training|TrainLoss: 0.33494827968571106|Train1Loss: 0.33494827968571106|ValidLoss: 0.3796706218237338|Iteration: 34200\n",
      "Training|TrainLoss: 0.334926684064839|Train1Loss: 0.334926684064839|ValidLoss: 0.3795604189619118|Iteration: 34300\n",
      "Training|TrainLoss: 0.33489948309050505|Train1Loss: 0.33489948309050505|ValidLoss: 0.37987414049081186|Iteration: 34400\n",
      "Training|TrainLoss: 0.33487729903696234|Train1Loss: 0.33487729903696234|ValidLoss: 0.3794539844329019|Iteration: 34500\n",
      "Training|TrainLoss: 0.33485994600752245|Train1Loss: 0.33485994600752245|ValidLoss: 0.37929643066213314|Iteration: 34600\n",
      "Training|TrainLoss: 0.3348254307747072|Train1Loss: 0.3348254307747072|ValidLoss: 0.37976357733420035|Iteration: 34700\n",
      "Training|TrainLoss: 0.3347934456180188|Train1Loss: 0.3347934456180188|ValidLoss: 0.37945299856729736|Iteration: 34800\n",
      "Training|TrainLoss: 0.33478396503314245|Train1Loss: 0.33478396503314245|ValidLoss: 0.37961615388605136|Iteration: 34900\n",
      "Training|TrainLoss: 0.334755742862224|Train1Loss: 0.334755742862224|ValidLoss: 0.3795729288336801|Iteration: 35000\n",
      "Training|TrainLoss: 0.33472877522522565|Train1Loss: 0.33472877522522565|ValidLoss: 0.3796141517645281|Iteration: 35100\n",
      "Training|TrainLoss: 0.33470657110753366|Train1Loss: 0.33470657110753366|ValidLoss: 0.379722234694543|Iteration: 35200\n",
      "Training|TrainLoss: 0.334676209008787|Train1Loss: 0.334676209008787|ValidLoss: 0.3793310373428636|Iteration: 35300\n",
      "Training|TrainLoss: 0.3346410344577404|Train1Loss: 0.3346410344577404|ValidLoss: 0.3792767012176354|Iteration: 35400\n",
      "Training|TrainLoss: 0.3346399563823202|Train1Loss: 0.3346399563823202|ValidLoss: 0.37895741116783965|Iteration: 35500\n",
      "Training|TrainLoss: 0.33458611315063896|Train1Loss: 0.33458611315063896|ValidLoss: 0.37890114721028567|Iteration: 35600\n",
      "Training|TrainLoss: 0.33452817114493255|Train1Loss: 0.33452817114493255|ValidLoss: 0.3788979801044795|Iteration: 35700\n",
      "Training|TrainLoss: 0.3345142952012342|Train1Loss: 0.3345142952012342|ValidLoss: 0.37859792609627024|Iteration: 35800\n",
      "Training|TrainLoss: 0.3344718319435634|Train1Loss: 0.3344718319435634|ValidLoss: 0.379076003576888|Iteration: 35900\n",
      "Training|TrainLoss: 0.3344312435489995|Train1Loss: 0.3344312435489995|ValidLoss: 0.3788397173908532|Iteration: 36000\n",
      "Training|TrainLoss: 0.3344028121946344|Train1Loss: 0.3344028121946344|ValidLoss: 0.37895343298151163|Iteration: 36100\n",
      "Training|TrainLoss: 0.334363136124365|Train1Loss: 0.334363136124365|ValidLoss: 0.3788443767326838|Iteration: 36200\n",
      "Training|TrainLoss: 0.334326497739265|Train1Loss: 0.334326497739265|ValidLoss: 0.3784251237720345|Iteration: 36300\n",
      "Training|TrainLoss: 0.33429681005376344|Train1Loss: 0.33429681005376344|ValidLoss: 0.3788097352328941|Iteration: 36400\n",
      "Training|TrainLoss: 0.33425720650805163|Train1Loss: 0.33425720650805163|ValidLoss: 0.37863741583770816|Iteration: 36500\n",
      "Training|TrainLoss: 0.33422397831640027|Train1Loss: 0.33422397831640027|ValidLoss: 0.37848461877534295|Iteration: 36600\n",
      "Training|TrainLoss: 0.334192126918755|Train1Loss: 0.334192126918755|ValidLoss: 0.3787456682861177|Iteration: 36700\n",
      "Training|TrainLoss: 0.3341570579662925|Train1Loss: 0.3341570579662925|ValidLoss: 0.3787394686526123|Iteration: 36800\n",
      "Training|TrainLoss: 0.3341266928874782|Train1Loss: 0.3341266928874782|ValidLoss: 0.3783150742983725|Iteration: 36900\n",
      "Training|TrainLoss: 0.33408058792088396|Train1Loss: 0.33408058792088396|ValidLoss: 0.3786549607031287|Iteration: 37000\n",
      "Training|TrainLoss: 0.334047263578988|Train1Loss: 0.334047263578988|ValidLoss: 0.37861355085794635|Iteration: 37100\n",
      "Training|TrainLoss: 0.33401277266277435|Train1Loss: 0.33401277266277435|ValidLoss: 0.37864932056252293|Iteration: 37200\n",
      "Training|TrainLoss: 0.333996961266309|Train1Loss: 0.333996961266309|ValidLoss: 0.37808878770885973|Iteration: 37300\n",
      "Training|TrainLoss: 0.33393289826120964|Train1Loss: 0.33393289826120964|ValidLoss: 0.37852211510895223|Iteration: 37400\n",
      "Training|TrainLoss: 0.33390167850391267|Train1Loss: 0.33390167850391267|ValidLoss: 0.37865233940827586|Iteration: 37500\n",
      "Training|TrainLoss: 0.3338703100201066|Train1Loss: 0.3338703100201066|ValidLoss: 0.37868948419176474|Iteration: 37600\n",
      "Training|TrainLoss: 0.333834188242723|Train1Loss: 0.333834188242723|ValidLoss: 0.3783166499363536|Iteration: 37700\n",
      "Training|TrainLoss: 0.33381747698966535|Train1Loss: 0.33381747698966535|ValidLoss: 0.37856973849283687|Iteration: 37800\n",
      "Training|TrainLoss: 0.33375671216218883|Train1Loss: 0.33375671216218883|ValidLoss: 0.3783831545269022|Iteration: 37900\n",
      "Training|TrainLoss: 0.3337348077335978|Train1Loss: 0.3337348077335978|ValidLoss: 0.3781205040526806|Iteration: 38000\n",
      "Training|TrainLoss: 0.333692678133063|Train1Loss: 0.333692678133063|ValidLoss: 0.3785256943088787|Iteration: 38100\n",
      "Training|TrainLoss: 0.3336476667560357|Train1Loss: 0.3336476667560357|ValidLoss: 0.3780333675076332|Iteration: 38200\n",
      "Training|TrainLoss: 0.33356429707262264|Train1Loss: 0.33356429707262264|ValidLoss: 0.37839766681767073|Iteration: 38300\n",
      "Training|TrainLoss: 0.33349892388856406|Train1Loss: 0.33349892388856406|ValidLoss: 0.3785648428445686|Iteration: 38400\n",
      "Training|TrainLoss: 0.33343598598150964|Train1Loss: 0.33343598598150964|ValidLoss: 0.37847106557350274|Iteration: 38500\n",
      "Training|TrainLoss: 0.3333899730510582|Train1Loss: 0.3333899730510582|ValidLoss: 0.3784551845851902|Iteration: 38600\n",
      "Training|TrainLoss: 0.3333545300391162|Train1Loss: 0.3333545300391162|ValidLoss: 0.3786950556424638|Iteration: 38700\n",
      "Training|TrainLoss: 0.33330838297174714|Train1Loss: 0.33330838297174714|ValidLoss: 0.378760162464144|Iteration: 38800\n",
      "Training|TrainLoss: 0.33327774773739305|Train1Loss: 0.33327774773739305|ValidLoss: 0.37886199493046063|Iteration: 38900\n",
      "Training|TrainLoss: 0.33324819645231385|Train1Loss: 0.33324819645231385|ValidLoss: 0.3788570336149726|Iteration: 39000\n",
      "Training|TrainLoss: 0.3332212343584991|Train1Loss: 0.3332212343584991|ValidLoss: 0.37893149153964495|Iteration: 39100\n",
      "Training|TrainLoss: 0.33319186432125536|Train1Loss: 0.33319186432125536|ValidLoss: 0.378924698437546|Iteration: 39200\n",
      "Training|TrainLoss: 0.3331836267271218|Train1Loss: 0.3331836267271218|ValidLoss: 0.37856771750499724|Iteration: 39300\n",
      "Training|TrainLoss: 0.33313779488149564|Train1Loss: 0.33313779488149564|ValidLoss: 0.3788597755718745|Iteration: 39400\n",
      "Training|TrainLoss: 0.3331541342030654|Train1Loss: 0.3331541342030654|ValidLoss: 0.3785417455869681|Iteration: 39500\n",
      "Training|TrainLoss: 0.33314032142157074|Train1Loss: 0.33314032142157074|ValidLoss: 0.37846025940224404|Iteration: 39600\n",
      "Training|TrainLoss: 0.33306754003938027|Train1Loss: 0.33306754003938027|ValidLoss: 0.3786401037117249|Iteration: 39700\n",
      "Training|TrainLoss: 0.3330231008851079|Train1Loss: 0.3330231008851079|ValidLoss: 0.3788852703854486|Iteration: 39800\n",
      "Training|TrainLoss: 0.33299610621093756|Train1Loss: 0.33299610621093756|ValidLoss: 0.3790008055919551|Iteration: 39900\n",
      "Training|TrainLoss: 0.33296933838409787|Train1Loss: 0.33296933838409787|ValidLoss: 0.3785863588757436|Iteration: 40000\n",
      "Training|TrainLoss: 0.33293991488453323|Train1Loss: 0.33293991488453323|ValidLoss: 0.3788035108157368|Iteration: 40100\n",
      "Training|TrainLoss: 0.33295885700797645|Train1Loss: 0.33295885700797645|ValidLoss: 0.3783890703721053|Iteration: 40200\n",
      "Training|TrainLoss: 0.33291133098640124|Train1Loss: 0.33291133098640124|ValidLoss: 0.37873360868128264|Iteration: 40300\n",
      "Training|TrainLoss: 0.33288581252523897|Train1Loss: 0.33288581252523897|ValidLoss: 0.37888599808884643|Iteration: 40400\n",
      "Training|TrainLoss: 0.3329082604752569|Train1Loss: 0.3329082604752569|ValidLoss: 0.3783420710272377|Iteration: 40500\n",
      "Training|TrainLoss: 0.3328872966583703|Train1Loss: 0.3328872966583703|ValidLoss: 0.37843087194689184|Iteration: 40600\n",
      "Training|TrainLoss: 0.3328493298912202|Train1Loss: 0.3328493298912202|ValidLoss: 0.3788286267007188|Iteration: 40700\n",
      "Training|TrainLoss: 0.33284175219094886|Train1Loss: 0.33284175219094886|ValidLoss: 0.37887613446472684|Iteration: 40800\n",
      "Training|TrainLoss: 0.3328264677980514|Train1Loss: 0.3328264677980514|ValidLoss: 0.37878266892819795|Iteration: 40900\n",
      "Training|TrainLoss: 0.33281373505119716|Train1Loss: 0.33281373505119716|ValidLoss: 0.37872994392275383|Iteration: 41000\n",
      "Training|TrainLoss: 0.3328017610446028|Train1Loss: 0.3328017610446028|ValidLoss: 0.3784596533224215|Iteration: 41100\n",
      "Training|TrainLoss: 0.3327917601035799|Train1Loss: 0.3327917601035799|ValidLoss: 0.3788122380962069|Iteration: 41200\n",
      "Training|TrainLoss: 0.3327772067040452|Train1Loss: 0.3327772067040452|ValidLoss: 0.3787379511914799|Iteration: 41300\n",
      "Training|TrainLoss: 0.332764774579672|Train1Loss: 0.332764774579672|ValidLoss: 0.37840933650266506|Iteration: 41400\n",
      "Training|TrainLoss: 0.3327521529132786|Train1Loss: 0.3327521529132786|ValidLoss: 0.37861246964156126|Iteration: 41500\n",
      "Training|TrainLoss: 0.3327589304969649|Train1Loss: 0.3327589304969649|ValidLoss: 0.3787382556743248|Iteration: 41600\n",
      "Training|TrainLoss: 0.33273074182269974|Train1Loss: 0.33273074182269974|ValidLoss: 0.3785194209015789|Iteration: 41700\n",
      "Training|TrainLoss: 0.3327274539920172|Train1Loss: 0.3327274539920172|ValidLoss: 0.3785997273396836|Iteration: 41800\n",
      "Training|TrainLoss: 0.33272696992374856|Train1Loss: 0.33272696992374856|ValidLoss: 0.3778928710113918|Iteration: 41900\n",
      "Training|TrainLoss: 0.3326981599332215|Train1Loss: 0.3326981599332215|ValidLoss: 0.3780860463254176|Iteration: 42000\n",
      "Training|TrainLoss: 0.3326765247105827|Train1Loss: 0.3326765247105827|ValidLoss: 0.3779905786653431|Iteration: 42100\n",
      "Training|TrainLoss: 0.3326651655953283|Train1Loss: 0.3326651655953283|ValidLoss: 0.37822175813678327|Iteration: 42200\n",
      "Training|TrainLoss: 0.3326485064113475|Train1Loss: 0.3326485064113475|ValidLoss: 0.37795138132771294|Iteration: 42300\n",
      "Training|TrainLoss: 0.33264919908695184|Train1Loss: 0.33264919908695184|ValidLoss: 0.37823149945563|Iteration: 42400\n",
      "Training|TrainLoss: 0.3326749100501676|Train1Loss: 0.3326749100501676|ValidLoss: 0.37747200312325224|Iteration: 42500\n",
      "Training|TrainLoss: 0.33264612075609046|Train1Loss: 0.33264612075609046|ValidLoss: 0.37766443347105816|Iteration: 42600\n",
      "Training|TrainLoss: 0.3326349107435099|Train1Loss: 0.3326349107435099|ValidLoss: 0.3775228394176779|Iteration: 42700\n",
      "Training|TrainLoss: 0.3326062742054491|Train1Loss: 0.3326062742054491|ValidLoss: 0.3777143261954691|Iteration: 42800\n",
      "Training|TrainLoss: 0.33261680103134694|Train1Loss: 0.33261680103134694|ValidLoss: 0.37737836304413946|Iteration: 42900\n",
      "Training|TrainLoss: 0.33260148770269865|Train1Loss: 0.33260148770269865|ValidLoss: 0.3776867111318632|Iteration: 43000\n",
      "Training|TrainLoss: 0.3325926596221298|Train1Loss: 0.3325926596221298|ValidLoss: 0.3776412477892438|Iteration: 43100\n",
      "Training|TrainLoss: 0.33258386055288125|Train1Loss: 0.33258386055288125|ValidLoss: 0.377631559279151|Iteration: 43200\n",
      "Training|TrainLoss: 0.33258174660200174|Train1Loss: 0.33258174660200174|ValidLoss: 0.37757462557088156|Iteration: 43300\n",
      "Training|TrainLoss: 0.3325741493111885|Train1Loss: 0.3325741493111885|ValidLoss: 0.3772538682533562|Iteration: 43400\n",
      "Training|TrainLoss: 0.33258828343268304|Train1Loss: 0.33258828343268304|ValidLoss: 0.3770095350802297|Iteration: 43500\n",
      "Training|TrainLoss: 0.3325545714222221|Train1Loss: 0.3325545714222221|ValidLoss: 0.37711394914969065|Iteration: 43600\n",
      "Training|TrainLoss: 0.33255425037844377|Train1Loss: 0.33255425037844377|ValidLoss: 0.37737484235483126|Iteration: 43700\n",
      "Training|TrainLoss: 0.33255518671027656|Train1Loss: 0.33255518671027656|ValidLoss: 0.3774248761253469|Iteration: 43800\n",
      "Training|TrainLoss: 0.3325404638369635|Train1Loss: 0.3325404638369635|ValidLoss: 0.3773474903746336|Iteration: 43900\n",
      "Training|TrainLoss: 0.33254093941336704|Train1Loss: 0.33254093941336704|ValidLoss: 0.37694775850647433|Iteration: 44000\n",
      "Training|TrainLoss: 0.3325132935862041|Train1Loss: 0.3325132935862041|ValidLoss: 0.37708311468614586|Iteration: 44100\n",
      "Training|TrainLoss: 0.3325023344162979|Train1Loss: 0.3325023344162979|ValidLoss: 0.37704387991781896|Iteration: 44200\n",
      "Training|TrainLoss: 0.3324940139033326|Train1Loss: 0.3324940139033326|ValidLoss: 0.37670498946058395|Iteration: 44300\n",
      "Training|TrainLoss: 0.33248164325803486|Train1Loss: 0.33248164325803486|ValidLoss: 0.37689248014916443|Iteration: 44400\n",
      "Training|TrainLoss: 0.33246391122601965|Train1Loss: 0.33246391122601965|ValidLoss: 0.37697405419107843|Iteration: 44500\n",
      "Training|TrainLoss: 0.3324793176333879|Train1Loss: 0.3324793176333879|ValidLoss: 0.37639340304313895|Iteration: 44600\n",
      "Training|TrainLoss: 0.33247624755341065|Train1Loss: 0.33247624755341065|ValidLoss: 0.37641035801649303|Iteration: 44700\n",
      "Training|TrainLoss: 0.33243721599558923|Train1Loss: 0.33243721599558923|ValidLoss: 0.37670764198595935|Iteration: 44800\n",
      "Training|TrainLoss: 0.332422301380567|Train1Loss: 0.332422301380567|ValidLoss: 0.37657690649770914|Iteration: 44900\n",
      "Training|TrainLoss: 0.3324237822302588|Train1Loss: 0.3324237822302588|ValidLoss: 0.3760670264562055|Iteration: 45000\n",
      "Training|TrainLoss: 0.3323822131032387|Train1Loss: 0.3323822131032387|ValidLoss: 0.3760717407810246|Iteration: 45100\n",
      "Training|TrainLoss: 0.332349854826668|Train1Loss: 0.332349854826668|ValidLoss: 0.3763668289726246|Iteration: 45200\n",
      "Training|TrainLoss: 0.332323354889502|Train1Loss: 0.332323354889502|ValidLoss: 0.3757603326259489|Iteration: 45300\n",
      "Training|TrainLoss: 0.33226458598524183|Train1Loss: 0.33226458598524183|ValidLoss: 0.37641762051519345|Iteration: 45400\n",
      "Training|TrainLoss: 0.33225336967842123|Train1Loss: 0.33225336967842123|ValidLoss: 0.37637810201461036|Iteration: 45500\n",
      "Training|TrainLoss: 0.3322336062043334|Train1Loss: 0.3322336062043334|ValidLoss: 0.3762917283688532|Iteration: 45600\n",
      "Training|TrainLoss: 0.3322212883398768|Train1Loss: 0.3322212883398768|ValidLoss: 0.37624108205741713|Iteration: 45700\n",
      "Training|TrainLoss: 0.33221225964248957|Train1Loss: 0.33221225964248957|ValidLoss: 0.3757927335773419|Iteration: 45800\n",
      "Training|TrainLoss: 0.3321856397915897|Train1Loss: 0.3321856397915897|ValidLoss: 0.3760362419686386|Iteration: 45900\n",
      "Training|TrainLoss: 0.3321654872666986|Train1Loss: 0.3321654872666986|ValidLoss: 0.37599087557531924|Iteration: 46000\n",
      "Training|TrainLoss: 0.3321621818775049|Train1Loss: 0.3321621818775049|ValidLoss: 0.3760220360688918|Iteration: 46100\n",
      "Training|TrainLoss: 0.3321354731243806|Train1Loss: 0.3321354731243806|ValidLoss: 0.37567114235401344|Iteration: 46200\n",
      "Training|TrainLoss: 0.3321040666658369|Train1Loss: 0.3321040666658369|ValidLoss: 0.3756670307873046|Iteration: 46300\n",
      "Training|TrainLoss: 0.3320728742450932|Train1Loss: 0.3320728742450932|ValidLoss: 0.3760777143461996|Iteration: 46400\n",
      "Training|TrainLoss: 0.3320452943732388|Train1Loss: 0.3320452943732388|ValidLoss: 0.375475476382717|Iteration: 46500\n",
      "Training|TrainLoss: 0.33198833171741937|Train1Loss: 0.33198833171741937|ValidLoss: 0.37567324461794976|Iteration: 46600\n",
      "Training|TrainLoss: 0.33196349107292406|Train1Loss: 0.33196349107292406|ValidLoss: 0.3761274537867806|Iteration: 46700\n",
      "Training|TrainLoss: 0.33193858670498594|Train1Loss: 0.33193858670498594|ValidLoss: 0.3760225776064678|Iteration: 46800\n",
      "Training|TrainLoss: 0.33189443883423236|Train1Loss: 0.33189443883423236|ValidLoss: 0.37561601071632383|Iteration: 46900\n",
      "Training|TrainLoss: 0.3318690178565257|Train1Loss: 0.3318690178565257|ValidLoss: 0.37549992221382045|Iteration: 47000\n",
      "Training|TrainLoss: 0.33182053800654876|Train1Loss: 0.33182053800654876|ValidLoss: 0.37590550375493614|Iteration: 47100\n",
      "Training|TrainLoss: 0.3318217921802286|Train1Loss: 0.3318217921802286|ValidLoss: 0.3754768542304337|Iteration: 47200\n",
      "Training|TrainLoss: 0.33176744995812696|Train1Loss: 0.33176744995812696|ValidLoss: 0.3759699571089672|Iteration: 47300\n",
      "Training|TrainLoss: 0.3317415383853995|Train1Loss: 0.3317415383853995|ValidLoss: 0.375663163358686|Iteration: 47400\n",
      "Training|TrainLoss: 0.33171224067545085|Train1Loss: 0.33171224067545085|ValidLoss: 0.3756121396503757|Iteration: 47500\n",
      "Training|TrainLoss: 0.33165735266970986|Train1Loss: 0.33165735266970986|ValidLoss: 0.3757622196718499|Iteration: 47600\n",
      "Training|TrainLoss: 0.3316377506010346|Train1Loss: 0.3316377506010346|ValidLoss: 0.3760026868901747|Iteration: 47700\n",
      "Training|TrainLoss: 0.33158484145603667|Train1Loss: 0.33158484145603667|ValidLoss: 0.3758795933556385|Iteration: 47800\n",
      "Training|TrainLoss: 0.3315515111210891|Train1Loss: 0.3315515111210891|ValidLoss: 0.3757711386016221|Iteration: 47900\n",
      "Training|TrainLoss: 0.33153240123776756|Train1Loss: 0.33153240123776756|ValidLoss: 0.3752735574089257|Iteration: 48000\n",
      "Training|TrainLoss: 0.33148944434917554|Train1Loss: 0.33148944434917554|ValidLoss: 0.37561548951437257|Iteration: 48100\n",
      "Training|TrainLoss: 0.33143772581214775|Train1Loss: 0.33143772581214775|ValidLoss: 0.3754953297949364|Iteration: 48200\n",
      "Training|TrainLoss: 0.33139904515207674|Train1Loss: 0.33139904515207674|ValidLoss: 0.37546859584524805|Iteration: 48300\n",
      "Training|TrainLoss: 0.3313783951197986|Train1Loss: 0.3313783951197986|ValidLoss: 0.37513340986683724|Iteration: 48400\n",
      "Training|TrainLoss: 0.3313250068890652|Train1Loss: 0.3313250068890652|ValidLoss: 0.375354028643331|Iteration: 48500\n",
      "Training|TrainLoss: 0.33129045816329167|Train1Loss: 0.33129045816329167|ValidLoss: 0.37507614552025315|Iteration: 48600\n",
      "Training|TrainLoss: 0.33125437730789004|Train1Loss: 0.33125437730789004|ValidLoss: 0.37500054145788203|Iteration: 48700\n",
      "Training|TrainLoss: 0.3312590336547521|Train1Loss: 0.3312590336547521|ValidLoss: 0.37452985517869913|Iteration: 48800\n",
      "Training|TrainLoss: 0.331188578818951|Train1Loss: 0.331188578818951|ValidLoss: 0.374992107006802|Iteration: 48900\n",
      "Training|TrainLoss: 0.3311762412451127|Train1Loss: 0.3311762412451127|ValidLoss: 0.3747168738839173|Iteration: 49000\n",
      "Training|TrainLoss: 0.3311482941093159|Train1Loss: 0.3311482941093159|ValidLoss: 0.37487101255020144|Iteration: 49100\n",
      "Training|TrainLoss: 0.3311019124903595|Train1Loss: 0.3311019124903595|ValidLoss: 0.3751175809370085|Iteration: 49200\n",
      "Training|TrainLoss: 0.33108565359760095|Train1Loss: 0.33108565359760095|ValidLoss: 0.37515969990001835|Iteration: 49300\n",
      "Training|TrainLoss: 0.3310531493006374|Train1Loss: 0.3310531493006374|ValidLoss: 0.3752029050741318|Iteration: 49400\n",
      "Training|TrainLoss: 0.331033919942703|Train1Loss: 0.331033919942703|ValidLoss: 0.3753076454986023|Iteration: 49500\n",
      "Training|TrainLoss: 0.33099936422547527|Train1Loss: 0.33099936422547527|ValidLoss: 0.37495187099261224|Iteration: 49600\n",
      "Training|TrainLoss: 0.33098119157328476|Train1Loss: 0.33098119157328476|ValidLoss: 0.3748849713254012|Iteration: 49700\n",
      "Training|TrainLoss: 0.33091839465206996|Train1Loss: 0.33091839465206996|ValidLoss: 0.3754266970863538|Iteration: 49800\n",
      "Training|TrainLoss: 0.3308532497981959|Train1Loss: 0.3308532497981959|ValidLoss: 0.3752895160647798|Iteration: 49900\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Initialize the network\n",
    "nn = NeuralNetwork(10,16,8,1)\n",
    "\n",
    "# Train the network\n",
    "nn.train(X_train,y_train_normalized,iterations=50000, learning_rate=0.01, lambda_reg=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Training Data Error Analysis\n",
      "RMSE:  0.5751523398467809\n",
      "MSE:  0.330800214031227\n",
      "MRE:  1.2501434971988037\n",
      "Raw Training Data Error Analysis\n",
      "RMSE:  5.934693871260008\n",
      "MSE:  35.22059134557111\n",
      "MRE:  196861299.0221328\n",
      "Normalized Validation Data Error Analysis\n",
      "RMSE:  0.6124917644740447\n",
      "MSE:  0.37514616154852864\n",
      "MRE:  2.9144674311693723\n",
      "Raw validation Data Error Analysis\n",
      "RMSE:  2.8561135268684454\n",
      "MSE:  8.15738447836091\n",
      "MRE:  0.45437618845664535\n",
      "Normalized Testing Data Error Analysis\n",
      "RMSE:  0.5420583757208355\n",
      "MSE:  0.2938272826891104\n",
      "MRE:  1.7564459995349626\n",
      "Raw Testing Data Error Analysis\n",
      "RMSE:  2.5276752260955875\n",
      "MSE:  6.38914204861738\n",
      "MRE:  0.4294518566788519\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Evaluation:TRAIN\n",
    "y_pred_train_normalized = nn.forward(X_train)\n",
    "\n",
    "#Evaluation:TRAIN => Error metrics for normalized data\n",
    "print(\"Normalized Training Data Error Analysis\")\n",
    "error_analysis(y_train_normalized, y_pred_train_normalized)\n",
    "\n",
    "#Evaluation:TRAIN => Error metrics for raw data\n",
    "print(\"Raw Training Data Error Analysis\")\n",
    "#compute raw prediction\n",
    "y_pred_train = y_pred_train_normalized * y_std + y_mean\n",
    "error_analysis(y_train, y_pred_train)\n",
    "\n",
    "#Evaluation:VAL\n",
    "y_pred_val_normalized = nn.forward(X_val)\n",
    "\n",
    "#Evaluation:VAL => Error metrics for normalized data\n",
    "print(\"Normalized Validation Data Error Analysis\")\n",
    "error_analysis(y_val_normalized, y_pred_val_normalized)\n",
    "\n",
    "#Evaluation:VAL => Error metrics for raw data\n",
    "print(\"Raw validation Data Error Analysis\")\n",
    "#compute raw prediction\n",
    "y_pred_val = y_pred_val_normalized * y_std + y_mean\n",
    "error_analysis(y_val, y_pred_val)\n",
    "\n",
    "#Evaluation:TEST\n",
    "y_pred_test_normalized = nn.forward(X_test)\n",
    "\n",
    "#Evaluation:TEST => Error metrics for normalized data\n",
    "print(\"Normalized Testing Data Error Analysis\")\n",
    "error_analysis(y_test_normalized, y_pred_test_normalized)\n",
    "\n",
    "#Evaluation:TEST => Error metrics for raw data\n",
    "print(\"Raw Testing Data Error Analysis\")\n",
    "#compute raw prediction\n",
    "y_pred_test = y_pred_test_normalized * y_std + y_mean\n",
    "error_analysis(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
