{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.system('cls')  # On Windows System\n",
    "\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('reset','-sf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Import numpy\n",
    "import matplotlib.pyplot as plt # Import pyplot\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "# plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the features and the labels for the training data and the test data\n",
    "# import the training data\n",
    "# train_data = pd.read_csv('train.csv')\n",
    "# test_data = pd.read_csv('test.csv')\n",
    "\n",
    "train_data = np.loadtxt('train.csv', delimiter=',', skiprows=1) \n",
    "test_data = np.loadtxt('test.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "train_data = train_data[:800]\n",
    "test_data = test_data[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.15521633e+03, 1.56950516e+03, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.09825450e+02,\n",
       "       0.00000000e+00, 1.00000000e+00, 4.25000000e+00])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(0.5 * len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = test_data[:split_index]\n",
    "test_data = test_data[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 11)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the training data using z-normalization \n",
    "mean = np.mean(train_data, axis=0)\n",
    "std = np.std(train_data, axis=0)\n",
    "normalized_train_data = (train_data - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the training data using z-normalization but using the training data mean and standard deviation\n",
    "# normalize the data using z-normalization \n",
    "normalized_test_data = (test_data - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # separate the training features from the labels \n",
    "# xtrain = train_data.iloc[:, :10]\n",
    "# ytrain = train_data.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separeate the test features from the labels\n",
    "# xtest= test_data.iloc[:, :10]\n",
    "# ytest = test_data.iloc[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid() function (activation function)\n",
    "def sigmoid(x):\n",
    "    fAct = 1/(1+np.exp(-1*x))\n",
    "    return fAct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leakyReLu(x, alpha=0.01):\n",
    "    fAct = np.where(x>0,x, alpha*x)\n",
    "    return fAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derived_leakyReLu(x, alpha=0.01):\n",
    "    fAct = np.where(x > 0, 1, alpha)\n",
    "    return fAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivation of the activation fucntion\n",
    "def derived_sigmoid(x):\n",
    "    fAct = 1/(1+np.exp(-1*x))\n",
    "    DfAct = fAct*(1-fAct)\n",
    "    return DfAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate m*n matrix, initial values are zeros\n",
    "def makematrix(m, n, fill=0.0):\n",
    "    a = []\n",
    "    for i in range(m):\n",
    "        a.append([fill]*n)\n",
    "    return np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random data\n",
    "def random_number(a,b):\n",
    "    return (b-a)*np.random.normal()+a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 11)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normalized_test_data[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO|Error: 191.16854|Iteration: 100\n",
      "INFO|Error: 186.78931|Iteration: 200\n",
      "INFO|Error: 184.55507|Iteration: 300\n",
      "INFO|Error: 183.21269|Iteration: 400\n",
      "INFO|Error: 182.29638|Iteration: 500\n",
      "INFO|Error: 181.59965|Iteration: 600\n",
      "INFO|Error: 181.04293|Iteration: 700\n",
      "INFO|Error: 180.58492|Iteration: 800\n",
      "INFO|Error: 180.19937|Iteration: 900\n",
      "INFO|Error: 179.86878|Iteration: 1000\n",
      "11.45\n",
      "rmse: 1583.1798620474917\n",
      "mae: 1492.6017815878292\n",
      "mre: 1057313.8523133888\n"
     ]
    }
   ],
   "source": [
    "#BP Neural Networks\n",
    "class BPNN:\n",
    "    def __init__(self, num_in, num_hidden, num_out):\n",
    "        # Nodes of input, hidden, output layers\n",
    "        self.num_in = num_in + 1  # Add one bias node\n",
    "        self.num_hidden = num_hidden + 1   # Add one bias node\n",
    "        self.num_out = num_out\n",
    "        \n",
    "        # Activate all nodes (vector)\n",
    "        self.active_in = np.array([1.0]*self.num_in) #creating a numpy array with the values of 1.0\n",
    "        self.active_hidden = np.array([1.0]*self.num_hidden)\n",
    "        self.active_out = np.array([1.0]*self.num_out)\n",
    "        \n",
    "        # Create weight matrices\n",
    "        self.wight_in = makematrix(self.num_in, self.num_hidden-1) \n",
    "        self.wight_out = makematrix(self.num_hidden, self.num_out)\n",
    "        \n",
    "        # Initialize weights\n",
    "        for i in range(self.num_in):\n",
    "            for j in range(self.num_hidden-1):\n",
    "                self.wight_in[i][j] = random_number(0.1, 0.1)\n",
    "        for i in range(self.num_hidden):\n",
    "            for j in range(self.num_out):\n",
    "                self.wight_out[i][j] = random_number(0.1, 0.1)\n",
    "\n",
    "        # Initialize bias\n",
    "        for j in range(self.num_hidden-1):\n",
    "            self.wight_in[0][j] = 0.1 \n",
    "        for j in range(self.num_out):\n",
    "            self.wight_out[0][j] = 0.1\n",
    "              \n",
    "    # Feed-forward\n",
    "    def Feedforward(self, inputs):\n",
    "        if np.shape(inputs)[1] != self.num_in-1:\n",
    "            raise ValueError('Incorrect input numbers')\n",
    "        \n",
    "        # Input layer values\n",
    "        self.active_in[1:self.num_in]=inputs #here we only get the last x withon the first which is the bias\n",
    "        \n",
    "        # Hidden layer values\n",
    "        self.sum_hidden=np.dot(self.wight_in.T,np.array([self.active_in]).T)\n",
    "        self.active_hidden = np.vstack( (1, sigmoid(self.sum_hidden)) )   # Activation function\n",
    "        \n",
    "        # Output layer values\n",
    "        self.sum_out=np.dot(self.wight_out.T,self.active_hidden)\n",
    "        self.active_out = self.sum_out # or sigmoid(self.sum_out)\n",
    "        return self.active_out\n",
    " \n",
    "    # Backpropagation\n",
    "    def errorbackpropagate(self, targets):   # lr is the learning rate\n",
    "        if self.num_out==1:\n",
    "            targets=targets\n",
    "        if np.shape(targets)[1] != self.num_out:\n",
    "            raise ValueError('Incorrect Output numbers')\n",
    "        # Cost function\n",
    "        self.error=(1/2)*np.dot((self.active_out-targets.T).T,(self.active_out-targets.T))\n",
    "        \n",
    "        # dJ/dw_out\n",
    "        self.gradient_out = (self.active_out-targets.T) #*derived_sigmoid(self.sum_out)#dJ/dx\n",
    "        self.gradient_w_out = np.dot(self.gradient_out,self.active_hidden.T).T #dx/dw_out\n",
    "        \n",
    "        # dJ/dw_in\n",
    "        self.gradient_hidden = np.dot(self.wight_out[1:],self.gradient_out)*derived_sigmoid(self.sum_hidden) #dJ/dx\n",
    "        self.gradient_w_in = np.dot(self.gradient_hidden,np.array([self.active_in])).T #dx/dw_in\n",
    "       \n",
    "        return self.error\n",
    "\n",
    "    def train(self, pattern, itera=1000, lr = 0.5):\n",
    "        # error = 100000\n",
    "        i=0\n",
    "        # while(error 10):\n",
    "        for i in range(itera):\n",
    "            Gradient_out = 0.0\n",
    "            Gradient_in = 0.0\n",
    "            error = 0\n",
    "            i+=1\n",
    "            for j in pattern:\n",
    "                inputs = np.array([j[0:self.num_in-1]])\n",
    "                \n",
    "                targets = np.array([j[self.num_in-1:]])\n",
    "                self.Feedforward(inputs)\n",
    "                self.errorbackpropagate(targets)\n",
    "                Gradient_out = Gradient_out + self.gradient_w_out\n",
    "                Gradient_in = Gradient_in + self.gradient_w_in\n",
    "            \n",
    "                error = error + self.error\n",
    "                \n",
    "            [Tm,Tn] = np.shape(pattern)\n",
    "            self.wight_out = self.wight_out - lr*Gradient_out/Tm\n",
    "            self.wight_in = self.wight_in - lr*Gradient_in/Tm \n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print('INFO|Error: %-.5f|Iteration: %d' %(error,i))\n",
    "            if i % 1000 == 0:\n",
    "                # Get current date in YYYYMMDD format\n",
    "                current_date = datetime.now().strftime('%Y%m%d%hh%mm') \n",
    "\n",
    "                # Create the files to store the weights with date and iteration number\n",
    "                weights_in_file = f'weights/weights_in_{current_date}_{i}.npy'\n",
    "                weights_out_file = f'weights/weights_out_{current_date}_{i}.npy'\n",
    "                np.save(weights_in_file, self.wight_in)\n",
    "                np.save(weights_out_file, self.wight_in)\n",
    "        \n",
    "    # Val prediction\n",
    "    def predict(self, patterns):\n",
    "        Pre = []\n",
    "        for i in patterns:\n",
    "            inputs = np.array([i[0:self.num_in-1]])\n",
    "            Pre.append( self.Feedforward(inputs) )\n",
    "            # print(Pre)\n",
    "        return Pre   \n",
    "\n",
    "\n",
    "n = BPNN(10, 16, 1) #Create neural networK \n",
    "n.train(normalized_train_data) # Training BP\n",
    "\n",
    "#After training predict using the training set\n",
    "y_t = n.predict(normalized_train_data)\n",
    "y_true_denorm = y_t * std + mean\n",
    "y_t_true = train_data[:,-1]\n",
    "print(y_t_true[0])\n",
    "epsilon = 1e-6  # Small value to avoid division by zero\n",
    "y_true_safe = np.where(y_t_true == 0, epsilon, y_t_true)\n",
    "\n",
    "y_t_pred = np.zeros((len(normalized_train_data[:,0]),))\n",
    "\n",
    "for i in range(len(y_true_denorm)):\n",
    "  y_t_pred[i] = y_true_denorm[i][0,0]\n",
    "\n",
    "rmse = np.sqrt(np.mean((y_t_true - y_t_pred) ** 2))\n",
    "mae = np.mean(np.abs(y_t_true - y_t_pred)) \n",
    "mre = np.mean(np.abs((y_t_true - y_t_pred) / y_true_safe))\n",
    "print(f'rmse: {rmse}')\n",
    "print(f'mae: {mae}')\n",
    "print(f'mre: {mre}')\n",
    "\n",
    "# n.weights() # check weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(y_t_true, y_t_pred)\n",
    "plt.plot([min(y_t_true), max(y_t_true)], [min(y_t_true), max(y_t_true)], color='red', linestyle='--')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Model Predictions vs True Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "187.65572\n",
    "179.86878"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
